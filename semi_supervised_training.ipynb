{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aced9888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7889d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(data_tensor, std=0.1):\n",
    "    \"\"\"Adds Gaussian noise to a PyTorch tensor.\"\"\"\n",
    "    noise = torch.randn_like(data_tensor) * std\n",
    "    return data_tensor + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6165d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98fc2634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 4]) torch.Size([150])\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "# sufle dataset before split\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(iris.data))\n",
    "iris.data = iris.data[indices]\n",
    "iris.target = iris.target[indices]\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "full_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(full_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data, validation_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "print(X_tensor.shape, y_tensor.shape)\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size = 1024\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size_train, shuffle=True)\n",
    "val_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eca498b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "output_size = 3\n",
    "model = SimpleNN(input_size, output_size)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "163701f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1500], Loss: 1.1172\n",
      "Validation Loss: 1.0355\n",
      "Best model saved!\n",
      "Epoch [20/1500], Loss: 1.0169\n",
      "Validation Loss: 1.0044\n",
      "Best model saved!\n",
      "Epoch [30/1500], Loss: 0.8882\n",
      "Validation Loss: 0.9597\n",
      "Best model saved!\n",
      "Epoch [40/1500], Loss: 0.7929\n",
      "Validation Loss: 0.9178\n",
      "Best model saved!\n",
      "Epoch [50/1500], Loss: 0.8094\n",
      "Validation Loss: 0.8965\n",
      "Best model saved!\n",
      "Epoch [60/1500], Loss: 0.7888\n",
      "Validation Loss: 0.8818\n",
      "Best model saved!\n",
      "Epoch [70/1500], Loss: 0.6870\n",
      "Validation Loss: 0.8675\n",
      "Best model saved!\n",
      "Epoch [80/1500], Loss: 0.6844\n",
      "Validation Loss: 0.8736\n",
      "Epoch [90/1500], Loss: 0.6467\n",
      "Validation Loss: 0.8644\n",
      "Best model saved!\n",
      "Epoch [100/1500], Loss: 0.6725\n",
      "Validation Loss: 0.8553\n",
      "Best model saved!\n",
      "Epoch [110/1500], Loss: 0.6672\n",
      "Validation Loss: 0.8475\n",
      "Best model saved!\n",
      "Epoch [120/1500], Loss: 0.6257\n",
      "Validation Loss: 0.8262\n",
      "Best model saved!\n",
      "Epoch [130/1500], Loss: 0.6366\n",
      "Validation Loss: 0.8159\n",
      "Best model saved!\n",
      "Epoch [140/1500], Loss: 0.6313\n",
      "Validation Loss: 0.8030\n",
      "Best model saved!\n",
      "Epoch [150/1500], Loss: 0.6132\n",
      "Validation Loss: 0.7953\n",
      "Best model saved!\n",
      "Epoch [160/1500], Loss: 0.6794\n",
      "Validation Loss: 0.7856\n",
      "Best model saved!\n",
      "Epoch [170/1500], Loss: 0.6070\n",
      "Validation Loss: 0.7779\n",
      "Best model saved!\n",
      "Epoch [180/1500], Loss: 0.5196\n",
      "Validation Loss: 0.7791\n",
      "Epoch [190/1500], Loss: 0.6529\n",
      "Validation Loss: 0.7725\n",
      "Best model saved!\n",
      "Epoch [200/1500], Loss: 0.5797\n",
      "Validation Loss: 0.7668\n",
      "Best model saved!\n",
      "Epoch [210/1500], Loss: 0.6153\n",
      "Validation Loss: 0.7501\n",
      "Best model saved!\n",
      "Epoch [220/1500], Loss: 0.6216\n",
      "Validation Loss: 0.7357\n",
      "Best model saved!\n",
      "Epoch [230/1500], Loss: 0.4816\n",
      "Validation Loss: 0.7345\n",
      "Best model saved!\n",
      "Epoch [240/1500], Loss: 0.6106\n",
      "Validation Loss: 0.7362\n",
      "Epoch [250/1500], Loss: 0.5464\n",
      "Validation Loss: 0.7266\n",
      "Best model saved!\n",
      "Epoch [260/1500], Loss: 0.4758\n",
      "Validation Loss: 0.7115\n",
      "Best model saved!\n",
      "Epoch [270/1500], Loss: 0.5810\n",
      "Validation Loss: 0.6891\n",
      "Best model saved!\n",
      "Epoch [280/1500], Loss: 0.6358\n",
      "Validation Loss: 0.6963\n",
      "Epoch [290/1500], Loss: 0.5181\n",
      "Validation Loss: 0.6936\n",
      "Epoch [300/1500], Loss: 0.5876\n",
      "Validation Loss: 0.6833\n",
      "Best model saved!\n",
      "Epoch [310/1500], Loss: 0.5619\n",
      "Validation Loss: 0.6764\n",
      "Best model saved!\n",
      "Epoch [320/1500], Loss: 0.5657\n",
      "Validation Loss: 0.6756\n",
      "Best model saved!\n",
      "Epoch [330/1500], Loss: 0.4382\n",
      "Validation Loss: 0.6753\n",
      "Best model saved!\n",
      "Epoch [340/1500], Loss: 0.4448\n",
      "Validation Loss: 0.6778\n",
      "Epoch [350/1500], Loss: 0.5169\n",
      "Validation Loss: 0.6633\n",
      "Best model saved!\n",
      "Epoch [360/1500], Loss: 0.4219\n",
      "Validation Loss: 0.6493\n",
      "Best model saved!\n",
      "Epoch [370/1500], Loss: 0.4980\n",
      "Validation Loss: 0.6585\n",
      "Epoch [380/1500], Loss: 0.4948\n",
      "Validation Loss: 0.6597\n",
      "Epoch [390/1500], Loss: 0.4191\n",
      "Validation Loss: 0.6436\n",
      "Best model saved!\n",
      "Epoch [400/1500], Loss: 0.5032\n",
      "Validation Loss: 0.6457\n",
      "Epoch [410/1500], Loss: 0.4135\n",
      "Validation Loss: 0.6341\n",
      "Best model saved!\n",
      "Epoch [420/1500], Loss: 0.3575\n",
      "Validation Loss: 0.6391\n",
      "Epoch [430/1500], Loss: 0.4960\n",
      "Validation Loss: 0.6297\n",
      "Best model saved!\n",
      "Epoch [440/1500], Loss: 0.4021\n",
      "Validation Loss: 0.6205\n",
      "Best model saved!\n",
      "Epoch [450/1500], Loss: 0.4710\n",
      "Validation Loss: 0.6166\n",
      "Best model saved!\n",
      "Epoch [460/1500], Loss: 0.4596\n",
      "Validation Loss: 0.6178\n",
      "Epoch [470/1500], Loss: 0.4225\n",
      "Validation Loss: 0.6168\n",
      "Epoch [480/1500], Loss: 0.3170\n",
      "Validation Loss: 0.6077\n",
      "Best model saved!\n",
      "Epoch [490/1500], Loss: 0.3970\n",
      "Validation Loss: 0.6085\n",
      "Epoch [500/1500], Loss: 0.4632\n",
      "Validation Loss: 0.6092\n",
      "Epoch [510/1500], Loss: 0.3926\n",
      "Validation Loss: 0.5946\n",
      "Best model saved!\n",
      "Epoch [520/1500], Loss: 0.4412\n",
      "Validation Loss: 0.5947\n",
      "Epoch [530/1500], Loss: 0.4158\n",
      "Validation Loss: 0.6026\n",
      "Epoch [540/1500], Loss: 0.4067\n",
      "Validation Loss: 0.5872\n",
      "Best model saved!\n",
      "Epoch [550/1500], Loss: 0.4277\n",
      "Validation Loss: 0.5828\n",
      "Best model saved!\n",
      "Epoch [560/1500], Loss: 0.4077\n",
      "Validation Loss: 0.5853\n",
      "Epoch [570/1500], Loss: 0.3893\n",
      "Validation Loss: 0.5772\n",
      "Best model saved!\n",
      "Epoch [580/1500], Loss: 0.4510\n",
      "Validation Loss: 0.5733\n",
      "Best model saved!\n",
      "Epoch [590/1500], Loss: 0.3390\n",
      "Validation Loss: 0.5725\n",
      "Best model saved!\n",
      "Epoch [600/1500], Loss: 0.4859\n",
      "Validation Loss: 0.5745\n",
      "Epoch [610/1500], Loss: 0.3669\n",
      "Validation Loss: 0.5602\n",
      "Best model saved!\n",
      "Epoch [620/1500], Loss: 0.3890\n",
      "Validation Loss: 0.5685\n",
      "Epoch [630/1500], Loss: 0.3601\n",
      "Validation Loss: 0.5531\n",
      "Best model saved!\n",
      "Epoch [640/1500], Loss: 0.3481\n",
      "Validation Loss: 0.5585\n",
      "Epoch [650/1500], Loss: 0.3644\n",
      "Validation Loss: 0.5608\n",
      "Epoch [660/1500], Loss: 0.3455\n",
      "Validation Loss: 0.5400\n",
      "Best model saved!\n",
      "Epoch [670/1500], Loss: 0.4164\n",
      "Validation Loss: 0.5453\n",
      "Epoch [680/1500], Loss: 0.3455\n",
      "Validation Loss: 0.5566\n",
      "Epoch [690/1500], Loss: 0.3848\n",
      "Validation Loss: 0.5471\n",
      "Epoch [700/1500], Loss: 0.3764\n",
      "Validation Loss: 0.5308\n",
      "Best model saved!\n",
      "Epoch [710/1500], Loss: 0.3263\n",
      "Validation Loss: 0.5380\n",
      "Epoch [720/1500], Loss: 0.4014\n",
      "Validation Loss: 0.5385\n",
      "Epoch [730/1500], Loss: 0.3810\n",
      "Validation Loss: 0.5325\n",
      "Epoch [740/1500], Loss: 0.3679\n",
      "Validation Loss: 0.5318\n",
      "Epoch [750/1500], Loss: 0.3957\n",
      "Validation Loss: 0.5173\n",
      "Best model saved!\n",
      "Epoch [760/1500], Loss: 0.3436\n",
      "Validation Loss: 0.5204\n",
      "Epoch [770/1500], Loss: 0.3730\n",
      "Validation Loss: 0.5252\n",
      "Epoch [780/1500], Loss: 0.3193\n",
      "Validation Loss: 0.5233\n",
      "Epoch [790/1500], Loss: 0.3529\n",
      "Validation Loss: 0.5207\n",
      "Epoch [800/1500], Loss: 0.3441\n",
      "Validation Loss: 0.5128\n",
      "Best model saved!\n",
      "Epoch [810/1500], Loss: 0.4256\n",
      "Validation Loss: 0.5093\n",
      "Best model saved!\n",
      "Epoch [820/1500], Loss: 0.2728\n",
      "Validation Loss: 0.5096\n",
      "Epoch [830/1500], Loss: 0.3666\n",
      "Validation Loss: 0.5092\n",
      "Best model saved!\n",
      "Epoch [840/1500], Loss: 0.3258\n",
      "Validation Loss: 0.5130\n",
      "Epoch [850/1500], Loss: 0.3249\n",
      "Validation Loss: 0.5007\n",
      "Best model saved!\n",
      "Epoch [860/1500], Loss: 0.3396\n",
      "Validation Loss: 0.5036\n",
      "Epoch [870/1500], Loss: 0.3746\n",
      "Validation Loss: 0.4974\n",
      "Best model saved!\n",
      "Epoch [880/1500], Loss: 0.2773\n",
      "Validation Loss: 0.4931\n",
      "Best model saved!\n",
      "Epoch [890/1500], Loss: 0.3669\n",
      "Validation Loss: 0.4968\n",
      "Epoch [900/1500], Loss: 0.3307\n",
      "Validation Loss: 0.4874\n",
      "Best model saved!\n",
      "Epoch [910/1500], Loss: 0.2810\n",
      "Validation Loss: 0.4841\n",
      "Best model saved!\n",
      "Epoch [920/1500], Loss: 0.3416\n",
      "Validation Loss: 0.4818\n",
      "Best model saved!\n",
      "Epoch [930/1500], Loss: 0.3068\n",
      "Validation Loss: 0.4836\n",
      "Epoch [940/1500], Loss: 0.2827\n",
      "Validation Loss: 0.4728\n",
      "Best model saved!\n",
      "Epoch [950/1500], Loss: 0.3211\n",
      "Validation Loss: 0.4813\n",
      "Epoch [960/1500], Loss: 0.3569\n",
      "Validation Loss: 0.4805\n",
      "Epoch [970/1500], Loss: 0.3495\n",
      "Validation Loss: 0.4741\n",
      "Epoch [980/1500], Loss: 0.2894\n",
      "Validation Loss: 0.4716\n",
      "Best model saved!\n",
      "Epoch [990/1500], Loss: 0.2836\n",
      "Validation Loss: 0.4635\n",
      "Best model saved!\n",
      "Epoch [1000/1500], Loss: 0.3460\n",
      "Validation Loss: 0.4767\n",
      "Epoch [1010/1500], Loss: 0.2493\n",
      "Validation Loss: 0.4673\n",
      "Epoch [1020/1500], Loss: 0.3126\n",
      "Validation Loss: 0.4660\n",
      "Epoch [1030/1500], Loss: 0.3340\n",
      "Validation Loss: 0.4580\n",
      "Best model saved!\n",
      "Epoch [1040/1500], Loss: 0.3325\n",
      "Validation Loss: 0.4657\n",
      "Epoch [1050/1500], Loss: 0.2909\n",
      "Validation Loss: 0.4524\n",
      "Best model saved!\n",
      "Epoch [1060/1500], Loss: 0.2528\n",
      "Validation Loss: 0.4669\n",
      "Epoch [1070/1500], Loss: 0.2961\n",
      "Validation Loss: 0.4584\n",
      "Epoch [1080/1500], Loss: 0.2622\n",
      "Validation Loss: 0.4541\n",
      "Epoch [1090/1500], Loss: 0.3033\n",
      "Validation Loss: 0.4523\n",
      "Best model saved!\n",
      "Epoch [1100/1500], Loss: 0.2888\n",
      "Validation Loss: 0.4547\n",
      "Epoch [1110/1500], Loss: 0.3147\n",
      "Validation Loss: 0.4600\n",
      "Epoch [1120/1500], Loss: 0.3042\n",
      "Validation Loss: 0.4409\n",
      "Best model saved!\n",
      "Epoch [1130/1500], Loss: 0.2966\n",
      "Validation Loss: 0.4421\n",
      "Epoch [1140/1500], Loss: 0.3156\n",
      "Validation Loss: 0.4458\n",
      "Epoch [1150/1500], Loss: 0.2306\n",
      "Validation Loss: 0.4446\n",
      "Epoch [1160/1500], Loss: 0.3033\n",
      "Validation Loss: 0.4459\n",
      "Epoch [1170/1500], Loss: 0.2480\n",
      "Validation Loss: 0.4413\n",
      "Epoch [1180/1500], Loss: 0.2883\n",
      "Validation Loss: 0.4337\n",
      "Best model saved!\n",
      "Epoch [1190/1500], Loss: 0.3211\n",
      "Validation Loss: 0.4308\n",
      "Best model saved!\n",
      "Epoch [1200/1500], Loss: 0.2358\n",
      "Validation Loss: 0.4270\n",
      "Best model saved!\n",
      "Epoch [1210/1500], Loss: 0.1934\n",
      "Validation Loss: 0.4343\n",
      "Epoch [1220/1500], Loss: 0.2726\n",
      "Validation Loss: 0.4354\n",
      "Epoch [1230/1500], Loss: 0.2689\n",
      "Validation Loss: 0.4270\n",
      "Best model saved!\n",
      "Epoch [1240/1500], Loss: 0.2763\n",
      "Validation Loss: 0.4284\n",
      "Epoch [1250/1500], Loss: 0.2570\n",
      "Validation Loss: 0.4322\n",
      "Epoch [1260/1500], Loss: 0.2716\n",
      "Validation Loss: 0.4211\n",
      "Best model saved!\n",
      "Epoch [1270/1500], Loss: 0.2919\n",
      "Validation Loss: 0.4206\n",
      "Best model saved!\n",
      "Epoch [1280/1500], Loss: 0.2539\n",
      "Validation Loss: 0.4165\n",
      "Best model saved!\n",
      "Epoch [1290/1500], Loss: 0.2652\n",
      "Validation Loss: 0.4143\n",
      "Best model saved!\n",
      "Epoch [1300/1500], Loss: 0.2383\n",
      "Validation Loss: 0.4156\n",
      "Epoch [1310/1500], Loss: 0.2266\n",
      "Validation Loss: 0.4075\n",
      "Best model saved!\n",
      "Epoch [1320/1500], Loss: 0.2570\n",
      "Validation Loss: 0.4198\n",
      "Epoch [1330/1500], Loss: 0.2683\n",
      "Validation Loss: 0.4189\n",
      "Epoch [1340/1500], Loss: 0.2748\n",
      "Validation Loss: 0.4112\n",
      "Epoch [1350/1500], Loss: 0.2305\n",
      "Validation Loss: 0.4071\n",
      "Best model saved!\n",
      "Epoch [1360/1500], Loss: 0.2517\n",
      "Validation Loss: 0.4049\n",
      "Best model saved!\n",
      "Epoch [1370/1500], Loss: 0.2668\n",
      "Validation Loss: 0.4102\n",
      "Epoch [1380/1500], Loss: 0.2909\n",
      "Validation Loss: 0.3999\n",
      "Best model saved!\n",
      "Epoch [1390/1500], Loss: 0.2337\n",
      "Validation Loss: 0.3990\n",
      "Best model saved!\n",
      "Epoch [1400/1500], Loss: 0.2384\n",
      "Validation Loss: 0.3979\n",
      "Best model saved!\n",
      "Epoch [1410/1500], Loss: 0.2321\n",
      "Validation Loss: 0.4034\n",
      "Epoch [1420/1500], Loss: 0.2602\n",
      "Validation Loss: 0.3999\n",
      "Epoch [1430/1500], Loss: 0.2220\n",
      "Validation Loss: 0.3919\n",
      "Best model saved!\n",
      "Epoch [1440/1500], Loss: 0.2227\n",
      "Validation Loss: 0.3941\n",
      "Epoch [1450/1500], Loss: 0.2867\n",
      "Validation Loss: 0.3922\n",
      "Epoch [1460/1500], Loss: 0.1777\n",
      "Validation Loss: 0.3913\n",
      "Best model saved!\n",
      "Epoch [1470/1500], Loss: 0.2254\n",
      "Validation Loss: 0.3979\n",
      "Epoch [1480/1500], Loss: 0.2498\n",
      "Validation Loss: 0.3852\n",
      "Best model saved!\n",
      "Epoch [1490/1500], Loss: 0.2567\n",
      "Validation Loss: 0.3905\n",
      "Epoch [1500/1500], Loss: 0.2098\n",
      "Validation Loss: 0.3790\n",
      "Best model saved!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1500\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = loss_function(val_outputs, val_labels)\n",
    "                val_losses.append(val_loss.item())\n",
    "            avg_val_loss = np.mean(val_losses)\n",
    "            print(f'Validation Loss: {avg_val_loss:.4f}')\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "                print('Best model saved!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aba731c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded the best_model.pth after training is complete\n",
    "best_model_path = 'best_model.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        test_outputs = model(test_inputs)\n",
    "        _, predicted = torch.max(test_outputs.data, 1)\n",
    "        total += test_labels.size(0)\n",
    "        correct += (predicted == test_labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test data: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24408d42",
   "metadata": {},
   "source": [
    "test now with half of the dataset of size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30ddc01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 4]) torch.Size([150])\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "# shuffle dataset before split\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(iris.data))\n",
    "iris.data = iris.data[indices]\n",
    "iris.target = iris.target[indices]\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "full_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# split with label and unlabel data. Assume 20% labeled data\n",
    "label_data, unlabel_data = train_test_split(full_dataset, test_size=0.8, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(label_data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data, validation_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "print(X_tensor.shape, y_tensor.shape)\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size = 1024\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size_train, shuffle=True)\n",
    "val_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "unlabeled_loader = DataLoader(unlabel_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5e46c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "output_size = 3\n",
    "model = SimpleNN(input_size, output_size)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae0f2805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Best model saved!\n",
      "Epoch [20/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [30/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [40/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [50/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [60/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [70/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [80/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [90/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [100/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [110/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [120/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [130/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [140/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [150/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [160/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [170/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [180/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [190/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [200/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [210/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [220/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [230/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [240/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [250/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [260/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [270/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [280/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [290/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [300/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [310/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [320/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [330/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [340/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [350/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [360/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [370/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [380/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [390/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [400/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [410/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [420/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [430/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [440/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [450/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [460/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [470/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [480/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [490/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [500/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [510/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [520/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [530/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [540/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [550/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [560/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [570/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [580/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [590/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [600/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [610/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [620/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [630/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [640/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [650/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [660/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [670/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [680/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [690/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [700/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [710/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [720/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [730/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [740/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [750/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [760/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [770/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [780/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [790/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [800/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [810/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [820/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [830/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [840/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [850/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [860/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [870/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [880/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [890/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [900/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [910/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [920/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [930/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [940/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [950/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [960/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [970/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [980/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [990/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1000/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1010/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1020/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1030/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1040/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1050/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1060/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1070/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1080/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1090/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1100/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1110/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1120/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1130/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1140/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1150/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1160/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1170/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1180/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1190/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1200/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1210/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1220/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1230/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1240/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1250/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1260/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1270/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1280/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1290/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1300/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1310/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1320/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1330/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1340/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1350/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1360/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1370/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1380/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1390/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1400/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1410/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1420/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1430/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1440/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1450/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1460/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1470/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1480/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1490/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1500/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1500\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = loss_function(val_outputs, val_labels)\n",
    "                val_losses.append(val_loss.item())\n",
    "            avg_val_loss = np.mean(val_losses)\n",
    "            print(f'Validation Loss: {avg_val_loss:.4f}')\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), 'best_model_label.pth')\n",
    "                print('Best model saved!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "865e3e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 66.67%\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded the best_model.pth after training is complete\n",
    "best_model_path = 'best_model_label.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        test_outputs = model(test_inputs)\n",
    "        _, predicted = torch.max(test_outputs.data, 1)\n",
    "        total += test_labels.size(0)\n",
    "        correct += (predicted == test_labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test data: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "36bf8c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the unlabel data: 79.17%\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded the best_model.pth after training is complete\n",
    "best_model_path = 'best_model_label.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for unlabel_inputs, unlabel_labels in unlabeled_loader:\n",
    "        unlabel_outputs = model(unlabel_inputs)\n",
    "        _, predicted = torch.max(unlabel_outputs.data, 1)\n",
    "        total += unlabel_labels.size(0)\n",
    "        correct += (predicted == unlabel_labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the unlabel data: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80514f4d",
   "metadata": {},
   "source": [
    "try using mean teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "257b133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73bc7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_teacher_weights(student_model, teacher_model, alpha=0.99):\n",
    "    for teacher_param, student_param in zip(teacher_model.parameters(), student_model.parameters()):\n",
    "        teacher_param.data.mul_(alpha).add_(student_param.data, alpha=1 - alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "464261bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "output_size = 3\n",
    "student_model = SimpleNN(input_size, output_size)\n",
    "# Instantiate the teacher model with the same architecture\n",
    "teacher_model = copy.deepcopy(student_model)\n",
    "\n",
    "# The teacher model should not have its gradients calculated\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "supervised_loss_fn = nn.CrossEntropyLoss()\n",
    "consistency_loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n",
    "alpha = 0.99  # for exponential moving average\n",
    "lambda_u = 0.3  # weight for unlabeled loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9260662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4411fc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 1.2190\n",
      "Validation Loss: 1.5891\n",
      "Best model saved!\n",
      "Epoch [20/1000], Loss: 1.1657\n",
      "Validation Loss: 1.5130\n",
      "Best model saved!\n",
      "Epoch [30/1000], Loss: 1.1193\n",
      "Validation Loss: 1.4467\n",
      "Best model saved!\n",
      "Epoch [40/1000], Loss: 1.0793\n",
      "Validation Loss: 1.3888\n",
      "Best model saved!\n",
      "Epoch [50/1000], Loss: 1.0418\n",
      "Validation Loss: 1.3376\n",
      "Best model saved!\n",
      "Epoch [60/1000], Loss: 1.0052\n",
      "Validation Loss: 1.2921\n",
      "Best model saved!\n",
      "Epoch [70/1000], Loss: 0.9700\n",
      "Validation Loss: 1.2502\n",
      "Best model saved!\n",
      "Epoch [80/1000], Loss: 0.9366\n",
      "Validation Loss: 1.2105\n",
      "Best model saved!\n",
      "Epoch [90/1000], Loss: 0.9044\n",
      "Validation Loss: 1.1729\n",
      "Best model saved!\n",
      "Epoch [100/1000], Loss: 0.8738\n",
      "Validation Loss: 1.1370\n",
      "Best model saved!\n",
      "Epoch [110/1000], Loss: 0.8433\n",
      "Validation Loss: 1.1026\n",
      "Best model saved!\n",
      "Epoch [120/1000], Loss: 0.8161\n",
      "Validation Loss: 1.0700\n",
      "Best model saved!\n",
      "Epoch [130/1000], Loss: 0.7900\n",
      "Validation Loss: 1.0390\n",
      "Best model saved!\n",
      "Epoch [140/1000], Loss: 0.7647\n",
      "Validation Loss: 1.0096\n",
      "Best model saved!\n",
      "Epoch [150/1000], Loss: 0.7398\n",
      "Validation Loss: 0.9818\n",
      "Best model saved!\n",
      "Epoch [160/1000], Loss: 0.7147\n",
      "Validation Loss: 0.9555\n",
      "Best model saved!\n",
      "Epoch [170/1000], Loss: 0.6915\n",
      "Validation Loss: 0.9307\n",
      "Best model saved!\n",
      "Epoch [180/1000], Loss: 0.6701\n",
      "Validation Loss: 0.9072\n",
      "Best model saved!\n",
      "Epoch [190/1000], Loss: 0.6517\n",
      "Validation Loss: 0.8851\n",
      "Best model saved!\n",
      "Epoch [200/1000], Loss: 0.6302\n",
      "Validation Loss: 0.8647\n",
      "Best model saved!\n",
      "Epoch [210/1000], Loss: 0.6137\n",
      "Validation Loss: 0.8455\n",
      "Best model saved!\n",
      "Epoch [220/1000], Loss: 0.5970\n",
      "Validation Loss: 0.8275\n",
      "Best model saved!\n",
      "Epoch [230/1000], Loss: 0.5823\n",
      "Validation Loss: 0.8105\n",
      "Best model saved!\n",
      "Epoch [240/1000], Loss: 0.5695\n",
      "Validation Loss: 0.7947\n",
      "Best model saved!\n",
      "Epoch [250/1000], Loss: 0.5541\n",
      "Validation Loss: 0.7799\n",
      "Best model saved!\n",
      "Epoch [260/1000], Loss: 0.5424\n",
      "Validation Loss: 0.7656\n",
      "Best model saved!\n",
      "Epoch [270/1000], Loss: 0.5303\n",
      "Validation Loss: 0.7523\n",
      "Best model saved!\n",
      "Epoch [280/1000], Loss: 0.5177\n",
      "Validation Loss: 0.7402\n",
      "Best model saved!\n",
      "Epoch [290/1000], Loss: 0.5079\n",
      "Validation Loss: 0.7287\n",
      "Best model saved!\n",
      "Epoch [300/1000], Loss: 0.4968\n",
      "Validation Loss: 0.7177\n",
      "Best model saved!\n",
      "Epoch [310/1000], Loss: 0.4886\n",
      "Validation Loss: 0.7074\n",
      "Best model saved!\n",
      "Epoch [320/1000], Loss: 0.4786\n",
      "Validation Loss: 0.6976\n",
      "Best model saved!\n",
      "Epoch [330/1000], Loss: 0.4700\n",
      "Validation Loss: 0.6887\n",
      "Best model saved!\n",
      "Epoch [340/1000], Loss: 0.4629\n",
      "Validation Loss: 0.6802\n",
      "Best model saved!\n",
      "Epoch [350/1000], Loss: 0.4565\n",
      "Validation Loss: 0.6723\n",
      "Best model saved!\n",
      "Epoch [360/1000], Loss: 0.4470\n",
      "Validation Loss: 0.6648\n",
      "Best model saved!\n",
      "Epoch [370/1000], Loss: 0.4420\n",
      "Validation Loss: 0.6569\n",
      "Best model saved!\n",
      "Epoch [380/1000], Loss: 0.4344\n",
      "Validation Loss: 0.6499\n",
      "Best model saved!\n",
      "Epoch [390/1000], Loss: 0.4275\n",
      "Validation Loss: 0.6439\n",
      "Best model saved!\n",
      "Epoch [400/1000], Loss: 0.4213\n",
      "Validation Loss: 0.6376\n",
      "Best model saved!\n",
      "Epoch [410/1000], Loss: 0.4188\n",
      "Validation Loss: 0.6315\n",
      "Best model saved!\n",
      "Epoch [420/1000], Loss: 0.4125\n",
      "Validation Loss: 0.6259\n",
      "Best model saved!\n",
      "Epoch [430/1000], Loss: 0.4083\n",
      "Validation Loss: 0.6207\n",
      "Best model saved!\n",
      "Epoch [440/1000], Loss: 0.4032\n",
      "Validation Loss: 0.6155\n",
      "Best model saved!\n",
      "Epoch [450/1000], Loss: 0.3974\n",
      "Validation Loss: 0.6104\n",
      "Best model saved!\n",
      "Epoch [460/1000], Loss: 0.3935\n",
      "Validation Loss: 0.6057\n",
      "Best model saved!\n",
      "Epoch [470/1000], Loss: 0.3886\n",
      "Validation Loss: 0.6015\n",
      "Best model saved!\n",
      "Epoch [480/1000], Loss: 0.3850\n",
      "Validation Loss: 0.5969\n",
      "Best model saved!\n",
      "Epoch [490/1000], Loss: 0.3800\n",
      "Validation Loss: 0.5928\n",
      "Best model saved!\n",
      "Epoch [500/1000], Loss: 0.3781\n",
      "Validation Loss: 0.5887\n",
      "Best model saved!\n",
      "Epoch [510/1000], Loss: 0.3737\n",
      "Validation Loss: 0.5850\n",
      "Best model saved!\n",
      "Epoch [520/1000], Loss: 0.3697\n",
      "Validation Loss: 0.5811\n",
      "Best model saved!\n",
      "Epoch [530/1000], Loss: 0.3649\n",
      "Validation Loss: 0.5775\n",
      "Best model saved!\n",
      "Epoch [540/1000], Loss: 0.3636\n",
      "Validation Loss: 0.5741\n",
      "Best model saved!\n",
      "Epoch [550/1000], Loss: 0.3590\n",
      "Validation Loss: 0.5709\n",
      "Best model saved!\n",
      "Epoch [560/1000], Loss: 0.3558\n",
      "Validation Loss: 0.5674\n",
      "Best model saved!\n",
      "Epoch [570/1000], Loss: 0.3528\n",
      "Validation Loss: 0.5644\n",
      "Best model saved!\n",
      "Epoch [580/1000], Loss: 0.3500\n",
      "Validation Loss: 0.5614\n",
      "Best model saved!\n",
      "Epoch [590/1000], Loss: 0.3496\n",
      "Validation Loss: 0.5585\n",
      "Best model saved!\n",
      "Epoch [600/1000], Loss: 0.3466\n",
      "Validation Loss: 0.5554\n",
      "Best model saved!\n",
      "Epoch [610/1000], Loss: 0.3418\n",
      "Validation Loss: 0.5526\n",
      "Best model saved!\n",
      "Epoch [620/1000], Loss: 0.3403\n",
      "Validation Loss: 0.5499\n",
      "Best model saved!\n",
      "Epoch [630/1000], Loss: 0.3370\n",
      "Validation Loss: 0.5472\n",
      "Best model saved!\n",
      "Epoch [640/1000], Loss: 0.3325\n",
      "Validation Loss: 0.5448\n",
      "Best model saved!\n",
      "Epoch [650/1000], Loss: 0.3306\n",
      "Validation Loss: 0.5421\n",
      "Best model saved!\n",
      "Epoch [660/1000], Loss: 0.3296\n",
      "Validation Loss: 0.5399\n",
      "Best model saved!\n",
      "Epoch [670/1000], Loss: 0.3266\n",
      "Validation Loss: 0.5376\n",
      "Best model saved!\n",
      "Epoch [680/1000], Loss: 0.3263\n",
      "Validation Loss: 0.5350\n",
      "Best model saved!\n",
      "Epoch [690/1000], Loss: 0.3231\n",
      "Validation Loss: 0.5330\n",
      "Best model saved!\n",
      "Epoch [700/1000], Loss: 0.3217\n",
      "Validation Loss: 0.5310\n",
      "Best model saved!\n",
      "Epoch [710/1000], Loss: 0.3179\n",
      "Validation Loss: 0.5288\n",
      "Best model saved!\n",
      "Epoch [720/1000], Loss: 0.3153\n",
      "Validation Loss: 0.5267\n",
      "Best model saved!\n",
      "Epoch [730/1000], Loss: 0.3120\n",
      "Validation Loss: 0.5247\n",
      "Best model saved!\n",
      "Epoch [740/1000], Loss: 0.3132\n",
      "Validation Loss: 0.5227\n",
      "Best model saved!\n",
      "Epoch [750/1000], Loss: 0.3091\n",
      "Validation Loss: 0.5206\n",
      "Best model saved!\n",
      "Epoch [760/1000], Loss: 0.3103\n",
      "Validation Loss: 0.5185\n",
      "Best model saved!\n",
      "Epoch [770/1000], Loss: 0.3066\n",
      "Validation Loss: 0.5169\n",
      "Best model saved!\n",
      "Epoch [780/1000], Loss: 0.3040\n",
      "Validation Loss: 0.5150\n",
      "Best model saved!\n",
      "Epoch [790/1000], Loss: 0.3014\n",
      "Validation Loss: 0.5130\n",
      "Best model saved!\n",
      "Epoch [800/1000], Loss: 0.2994\n",
      "Validation Loss: 0.5111\n",
      "Best model saved!\n",
      "Epoch [810/1000], Loss: 0.2975\n",
      "Validation Loss: 0.5096\n",
      "Best model saved!\n",
      "Epoch [820/1000], Loss: 0.2963\n",
      "Validation Loss: 0.5078\n",
      "Best model saved!\n",
      "Epoch [830/1000], Loss: 0.2953\n",
      "Validation Loss: 0.5060\n",
      "Best model saved!\n",
      "Epoch [840/1000], Loss: 0.2937\n",
      "Validation Loss: 0.5046\n",
      "Best model saved!\n",
      "Epoch [850/1000], Loss: 0.2905\n",
      "Validation Loss: 0.5030\n",
      "Best model saved!\n",
      "Epoch [860/1000], Loss: 0.2890\n",
      "Validation Loss: 0.5013\n",
      "Best model saved!\n",
      "Epoch [870/1000], Loss: 0.2865\n",
      "Validation Loss: 0.4999\n",
      "Best model saved!\n",
      "Epoch [880/1000], Loss: 0.2875\n",
      "Validation Loss: 0.4984\n",
      "Best model saved!\n",
      "Epoch [890/1000], Loss: 0.2848\n",
      "Validation Loss: 0.4967\n",
      "Best model saved!\n",
      "Epoch [900/1000], Loss: 0.2835\n",
      "Validation Loss: 0.4953\n",
      "Best model saved!\n",
      "Epoch [910/1000], Loss: 0.2833\n",
      "Validation Loss: 0.4939\n",
      "Best model saved!\n",
      "Epoch [920/1000], Loss: 0.2808\n",
      "Validation Loss: 0.4925\n",
      "Best model saved!\n",
      "Epoch [930/1000], Loss: 0.2789\n",
      "Validation Loss: 0.4912\n",
      "Best model saved!\n",
      "Epoch [940/1000], Loss: 0.2772\n",
      "Validation Loss: 0.4897\n",
      "Best model saved!\n",
      "Epoch [950/1000], Loss: 0.2762\n",
      "Validation Loss: 0.4884\n",
      "Best model saved!\n",
      "Epoch [960/1000], Loss: 0.2720\n",
      "Validation Loss: 0.4872\n",
      "Best model saved!\n",
      "Epoch [970/1000], Loss: 0.2719\n",
      "Validation Loss: 0.4857\n",
      "Best model saved!\n",
      "Epoch [980/1000], Loss: 0.2713\n",
      "Validation Loss: 0.4842\n",
      "Best model saved!\n",
      "Epoch [990/1000], Loss: 0.2703\n",
      "Validation Loss: 0.4833\n",
      "Best model saved!\n",
      "Epoch [1000/1000], Loss: 0.2667\n",
      "Validation Loss: 0.4820\n",
      "Best model saved!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 1000\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    student_model.train()\n",
    "    for (labeled_data, labeled_labels), (unlabeled_data,_) in zip(cycle(train_loader), unlabeled_loader):\n",
    "        # Supervised loss\n",
    "        labeled_outputs = student_model(labeled_data)\n",
    "        supervised_loss = supervised_loss_fn(labeled_outputs, labeled_labels)\n",
    "        \n",
    "        # 1. Weakly augmented view for the TEACHER\n",
    "        unlabeled_data_teacher = add_gaussian_noise(unlabeled_data, std=0.05)\n",
    "        \n",
    "        # 2. Strongly augmented view for the STUDENT\n",
    "        unlabeled_data_student = add_gaussian_noise(unlabeled_data, std=0.15)\n",
    "        \n",
    "        # Consistency loss\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(unlabeled_data_teacher)\n",
    "        student_outputs_unlabeled = student_model(unlabeled_data_student)\n",
    "        consistency_loss = consistency_loss_fn(student_outputs_unlabeled, teacher_outputs)\n",
    "\n",
    "        total_loss = supervised_loss + lambda_u * consistency_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update teacher model's weights using EMA\n",
    "        update_teacher_weights(student_model, teacher_model)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss .item():.4f}')\n",
    "            # Evaluate on validation set\n",
    "            student_model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_losses = []\n",
    "                for val_inputs, val_labels in val_loader:\n",
    "                    val_outputs = student_model(val_inputs)\n",
    "                    val_loss = loss_function(val_outputs, val_labels)\n",
    "                    val_losses.append(val_loss.item())\n",
    "                avg_val_loss = np.mean(val_losses)\n",
    "                print(f'Validation Loss: {avg_val_loss:.4f}')\n",
    "                if avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    torch.save(student_model.state_dict(), 'best_model_label_and_unlabel.pth')\n",
    "                    print('Best model saved!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "35cf9702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded the best_model.pth after training is complete\n",
    "best_model_path = 'best_model_label_and_unlabel.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        test_outputs = model(test_inputs)\n",
    "        _, predicted = torch.max(test_outputs.data, 1)\n",
    "        total += test_labels.size(0)\n",
    "        correct += (predicted == test_labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test data: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "df547014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the unlabel data: 95.00%\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded the best_model.pth after training is complete\n",
    "best_model_path = 'best_model_label_and_unlabel.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for unlabel_inputs, unlabel_labels in unlabeled_loader:\n",
    "        unlabel_outputs = model(unlabel_inputs)\n",
    "        _, predicted = torch.max(unlabel_outputs.data, 1)\n",
    "        total += unlabel_labels.size(0)\n",
    "        correct += (predicted == unlabel_labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the unlabel data: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semi-supervised-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
