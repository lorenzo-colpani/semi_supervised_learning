{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aced9888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from itertools import cycle\n",
    "import copy\n",
    "import mlflow\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d4a0f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c17800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_experiment(experiment_name):\n",
    "  \"\"\"\n",
    "  Retrieve the ID of an existing MLflow experiment or create a new one if it doesn't exist.\n",
    "\n",
    "  This function checks if an experiment with the given name exists within MLflow.\n",
    "  If it does, the function returns its ID. If not, it creates a new experiment\n",
    "  with the provided name and returns its ID.\n",
    "\n",
    "  Parameters:\n",
    "  - experiment_name (str): Name of the MLflow experiment.\n",
    "\n",
    "  Returns:\n",
    "  - str: ID of the existing or newly created MLflow experiment.\n",
    "  \"\"\"\n",
    "\n",
    "  if experiment := mlflow.get_experiment_by_name(experiment_name):\n",
    "      return experiment.experiment_id\n",
    "  else:\n",
    "      return mlflow.create_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd37b1c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "API request to http://localhost:8080/api/2.0/mlflow/experiments/get-by-name failed with exception HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=mean+teacher (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000286FE156BE0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\urllib3\\connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNewConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:493\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\urllib3\\connection.py:494\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28mself\u001b[39m.putheader(header, value)\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.13.7-windows-x86_64-none\\Lib\\http\\client.py:1333\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1332\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1333\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.13.7-windows-x86_64-none\\Lib\\http\\client.py:1093\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1096\u001b[39m \n\u001b[32m   1097\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.13.7-windows-x86_64-none\\Lib\\http\\client.py:1037\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\urllib3\\connection.py:325\u001b[39m, in \u001b[36mHTTPConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n\u001b[32m    327\u001b[39m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\urllib3\\connection.py:213\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[32m    214\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    215\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    217\u001b[39m sys.audit(\u001b[33m\"\u001b[39m\u001b[33mhttp.client.connect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m.port)\n",
      "\u001b[31mNewConnectionError\u001b[39m: <urllib3.connection.HTTPConnection object at 0x00000286FE156BE0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "    \u001b[31m[... skipping similar frames: HTTPConnectionPool.urlopen at line 871 (4 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=mean+teacher (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000286FE156BE0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:230\u001b[39m, in \u001b[36mhttp_request\u001b[39m\u001b[34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, retry_timeout_seconds, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_http_response_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackoff_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackoff_jitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_codes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraise_on_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost_creds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrespect_retry_after_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrespect_retry_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.Timeout \u001b[38;5;28;01mas\u001b[39;00m to:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\mlflow\\utils\\request_utils.py:237\u001b[39m, in \u001b[36m_get_http_response_with_retries\u001b[39m\u001b[34m(method, url, max_retries, backoff_factor, backoff_jitter, retry_codes, raise_on_status, allow_redirects, respect_retry_after_header, **kwargs)\u001b[39m\n\u001b[32m    235\u001b[39m allow_redirects = env_value \u001b[38;5;28;01mif\u001b[39;00m allow_redirects \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m allow_redirects\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\requests\\adapters.py:677\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    675\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mConnectionError\u001b[39m: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=mean+teacher (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000286FE156BE0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m experiment_id = \u001b[43mget_or_create_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean teacher\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Set the current active MLflow experiment\u001b[39;00m\n\u001b[32m      4\u001b[39m mlflow.set_experiment(experiment_id=experiment_id)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mget_or_create_experiment\u001b[39m\u001b[34m(experiment_name)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_or_create_experiment\u001b[39m(experiment_name):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m  Retrieve the ID of an existing MLflow experiment or create a new one if it doesn't exist.\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[33;03m  - str: ID of the existing or newly created MLflow experiment.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m experiment := \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     17\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m experiment.experiment_id\n\u001b[32m     18\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:1926\u001b[39m, in \u001b[36mget_experiment_by_name\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m   1892\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_experiment_by_name\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) -> Experiment | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1893\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1894\u001b[39m \u001b[33;03m    Retrieve an experiment by experiment name from the backend store\u001b[39;00m\n\u001b[32m   1895\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1924\u001b[39m \u001b[33;03m        Creation timestamp: 1662004217511\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1926\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\mlflow\\tracking\\client.py:1770\u001b[39m, in \u001b[36mMlflowClient.get_experiment_by_name\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_experiment_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Experiment | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1739\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Retrieve an experiment by experiment name from the backend store\u001b[39;00m\n\u001b[32m   1740\u001b[39m \n\u001b[32m   1741\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1768\u001b[39m \u001b[33;03m        Lifecycle_stage: active\u001b[39;00m\n\u001b[32m   1769\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1770\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:279\u001b[39m, in \u001b[36mTrackingServiceClient.get_experiment_by_name\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_experiment_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[32m    272\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    273\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    274\u001b[39m \u001b[33;03m        name: The experiment name.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    277\u001b[39m \u001b[33;03m        :py:class:`mlflow.entities.Experiment`\u001b[39;00m\n\u001b[32m    278\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:855\u001b[39m, in \u001b[36mRestStore.get_experiment_by_name\u001b[39m\u001b[34m(self, experiment_name)\u001b[39m\n\u001b[32m    853\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    854\u001b[39m     req_body = message_to_json(GetExperimentByName(experiment_name=experiment_name))\n\u001b[32m--> \u001b[39m\u001b[32m855\u001b[39m     response_proto = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGetExperimentByName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    856\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Experiment.from_proto(response_proto.experiment)\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MlflowException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:200\u001b[39m, in \u001b[36mRestStore._call_endpoint\u001b[39m\u001b[34m(self, api, json_body, endpoint, retry_timeout_seconds)\u001b[39m\n\u001b[32m    198\u001b[39m     endpoint, method = _METHOD_TO_INFO[api]\n\u001b[32m    199\u001b[39m response_proto = api.Response()\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:549\u001b[39m, in \u001b[36mcall_endpoint\u001b[39m\u001b[34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mGET\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    548\u001b[39m     call_kwargs[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m] = json_body\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m     response = \u001b[43mhttp_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    551\u001b[39m     call_kwargs[\u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m] = json_body\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:253\u001b[39m, in \u001b[36mhttp_request\u001b[39m\u001b[34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, retry_timeout_seconds, **kwargs)\u001b[39m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUrlException(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01miu\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPI request to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m failed with exception \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mMlflowException\u001b[39m: API request to http://localhost:8080/api/2.0/mlflow/experiments/get-by-name failed with exception HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=mean+teacher (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000286FE156BE0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))"
     ]
    }
   ],
   "source": [
    "experiment_id = get_or_create_experiment(\"mean teacher\")\n",
    "\n",
    "# Set the current active MLflow experiment\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "\n",
    "# override Optuna's default logging to ERROR only\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8142e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.optuna.storage import MlflowStorage\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name('test').experiment_id\n",
    "\n",
    "mlflow_storage = MlflowStorage(experiment_id=experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0810d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def champion_callback(study, frozen_trial):\n",
    "  \"\"\"\n",
    "  Logging callback that will report when a new trial iteration improves upon existing\n",
    "  best trial values.\n",
    "\n",
    "  Note: This callback is not intended for use in distributed computing systems such as Spark\n",
    "  or Ray due to the micro-batch iterative implementation for distributing trials to a cluster's\n",
    "  workers or agents.\n",
    "  The race conditions with file system state management for distributed trials will render\n",
    "  inconsistent values with this callback.\n",
    "  \"\"\"\n",
    "\n",
    "  winner = study.user_attrs.get(\"winner\", None)\n",
    "\n",
    "  if study.best_value and winner != study.best_value:\n",
    "      study.set_user_attr(\"winner\", study.best_value)\n",
    "      if winner:\n",
    "          improvement_percent = (abs(winner - study.best_value) / study.best_value) * 100\n",
    "          print(\n",
    "              f\"Trial {frozen_trial.number} achieved value: {frozen_trial.value} with \"\n",
    "              f\"{improvement_percent: .4f}% improvement\"\n",
    "          )\n",
    "      else:\n",
    "          print(f\"Initial trial {frozen_trial.number} achieved value: {frozen_trial.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7889d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(data_tensor, std=0.1):\n",
    "    \"\"\"Adds Gaussian noise to a PyTorch tensor.\"\"\"\n",
    "    noise = torch.randn_like(data_tensor) * std\n",
    "    return data_tensor + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6165d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98fc2634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 4]) torch.Size([150])\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "# sufle dataset before split\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(iris.data))\n",
    "iris.data = iris.data[indices]\n",
    "iris.target = iris.target[indices]\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "full_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(full_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data, validation_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "print(X_tensor.shape, y_tensor.shape)\n",
    "\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "val_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f87cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start an optuna study to minimize the validation loss\n",
    "def objective(trial):\n",
    "    with mlflow.start_run(nested=True):\n",
    "    \n",
    "        params = {\n",
    "            'batch_size_train': trial.suggest_categorical('batch_size_train', [16, 32, 64, 128, 256, 512, 1024])\n",
    "            ,'lr': trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "            ,'num_epochs': trial.suggest_int('num_epochs', 50, 500)\n",
    "        }\n",
    "        \n",
    "        batch_size_train = params['batch_size_train']\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size_train, shuffle=True)\n",
    "        input_size = 4\n",
    "        output_size = 3\n",
    "        model = SimpleNN(input_size, output_size)\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "\n",
    "        for epoch in range(params['num_epochs']):\n",
    "            # Training\n",
    "            model.train()\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                _, predicted_train = torch.max(outputs.data, 1)\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (predicted_train == labels).sum().item()\n",
    "                loss = loss_function(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            validation_accuracy = correct_val / total_val\n",
    "\n",
    "            # Evaluate on validation set\n",
    "            model.eval()\n",
    "            correct_val = 0\n",
    "            total_val = 0\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_labels in val_loader:\n",
    "                    val_outputs = model(val_inputs)\n",
    "                    _, predicted_val = torch.max(val_outputs.data, 1)\n",
    "                    total_val += val_labels.size(0)\n",
    "                    correct_val += (predicted_val == val_labels).sum().item()\n",
    "            validation_accuracy = correct_val / total_val\n",
    "            trial.report(validation_accuracy, epoch)\n",
    "            \n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "        \n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric('train accuracy', validation_accuracy)\n",
    "        mlflow.log_metric('validation accuracy', validation_accuracy)\n",
    "        \n",
    "            \n",
    "    return validation_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7845c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 14:04:39,601] A new study created in RDB with name: supervised_iris_study\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the storage location and a name for your study\n",
    "storage_name = \"sqlite:///my_optuna_study.db\"\n",
    "study_name = \"supervised_iris_study\"\n",
    "pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=30, interval_steps=10)\n",
    "# Create a study object and specify the direction is to maximize accuracy.\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner, storage=storage_name, study_name=study_name, load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3083f88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 14:04:56,359] Trial 0 finished with value: 0.4583333333333333 and parameters: {'batch_size_train': 32, 'lr': 0.0005377518515919115, 'num_epochs': 395}. Best is trial 0 with value: 0.4583333333333333.\n",
      "[I 2025-09-29 14:05:02,338] Trial 1 finished with value: 0.8333333333333334 and parameters: {'batch_size_train': 16, 'lr': 0.00626446907455853, 'num_epochs': 160}. Best is trial 1 with value: 0.8333333333333334.\n",
      "[I 2025-09-29 14:05:08,873] Trial 2 finished with value: 0.5416666666666666 and parameters: {'batch_size_train': 64, 'lr': 4.941433846982852e-05, 'num_epochs': 272}. Best is trial 1 with value: 0.8333333333333334.\n",
      "[I 2025-09-29 14:05:20,048] Trial 3 finished with value: 0.5833333333333334 and parameters: {'batch_size_train': 64, 'lr': 0.0012520065381267458, 'num_epochs': 464}. Best is trial 1 with value: 0.8333333333333334.\n",
      "[I 2025-09-29 14:05:26,357] Trial 4 finished with value: 0.16666666666666666 and parameters: {'batch_size_train': 16, 'lr': 4.938551275989298e-05, 'num_epochs': 256}. Best is trial 1 with value: 0.8333333333333334.\n",
      "[I 2025-09-29 14:05:26,916] Trial 5 pruned. \n",
      "[I 2025-09-29 14:05:27,463] Trial 6 pruned. \n",
      "[I 2025-09-29 14:05:33,587] Trial 7 finished with value: 0.8333333333333334 and parameters: {'batch_size_train': 1024, 'lr': 0.0005238199450840239, 'num_epochs': 278}. Best is trial 1 with value: 0.8333333333333334.\n",
      "[I 2025-09-29 14:05:40,182] Trial 8 pruned. \n",
      "[I 2025-09-29 14:05:40,774] Trial 9 pruned. \n",
      "[I 2025-09-29 14:05:41,379] Trial 10 pruned. \n",
      "[I 2025-09-29 14:05:42,029] Trial 11 pruned. \n",
      "[I 2025-09-29 14:05:42,646] Trial 12 pruned. \n",
      "[I 2025-09-29 14:05:43,452] Trial 13 pruned. \n",
      "[I 2025-09-29 14:05:44,019] Trial 14 pruned. \n",
      "[I 2025-09-29 14:05:47,451] Trial 15 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 512, 'lr': 0.06059806288997263, 'num_epochs': 181}. Best is trial 15 with value: 0.9166666666666666.\n",
      "[I 2025-09-29 14:05:48,876] Trial 16 finished with value: 0.8333333333333334 and parameters: {'batch_size_train': 512, 'lr': 0.0909474322447322, 'num_epochs': 55}. Best is trial 15 with value: 0.9166666666666666.\n",
      "[I 2025-09-29 14:05:53,325] Trial 17 finished with value: 0.7083333333333334 and parameters: {'batch_size_train': 512, 'lr': 0.021410842981115345, 'num_epochs': 190}. Best is trial 15 with value: 0.9166666666666666.\n",
      "[I 2025-09-29 14:05:56,384] Trial 18 pruned. \n",
      "[I 2025-09-29 14:05:58,303] Trial 19 finished with value: 0.6666666666666666 and parameters: {'batch_size_train': 256, 'lr': 0.025954318355295346, 'num_epochs': 95}. Best is trial 15 with value: 0.9166666666666666.\n",
      "[I 2025-09-29 14:06:00,921] Trial 20 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 16, 'lr': 0.04024916340797828, 'num_epochs': 95}. Best is trial 15 with value: 0.9166666666666666.\n",
      "[I 2025-09-29 14:06:01,738] Trial 21 pruned. \n",
      "[I 2025-09-29 14:06:05,332] Trial 22 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 16, 'lr': 0.03669955807371576, 'num_epochs': 111}. Best is trial 15 with value: 0.9166666666666666.\n",
      "[I 2025-09-29 14:06:08,358] Trial 23 finished with value: 0.875 and parameters: {'batch_size_train': 512, 'lr': 0.037814911011309356, 'num_epochs': 119}. Best is trial 15 with value: 0.9166666666666666.\n",
      "[I 2025-09-29 14:06:13,568] Trial 24 finished with value: 0.875 and parameters: {'batch_size_train': 16, 'lr': 0.08150966148318933, 'num_epochs': 200}. Best is trial 15 with value: 0.9166666666666666.\n",
      "[I 2025-09-29 14:06:15,656] Trial 25 finished with value: 0.875 and parameters: {'batch_size_train': 16, 'lr': 0.015929288965524334, 'num_epochs': 92}. Best is trial 15 with value: 0.9166666666666666.\n",
      "[I 2025-09-29 14:06:20,165] Trial 26 finished with value: 0.8333333333333334 and parameters: {'batch_size_train': 512, 'lr': 0.05246392007010606, 'num_epochs': 216}. Best is trial 15 with value: 0.9166666666666666.\n",
      "[I 2025-09-29 14:06:21,373] Trial 27 pruned. \n",
      "[I 2025-09-29 14:06:22,233] Trial 28 pruned. \n",
      "[I 2025-09-29 14:06:23,457] Trial 29 finished with value: 0.4583333333333333 and parameters: {'batch_size_train': 128, 'lr': 0.039008913352226955, 'num_epochs': 54}. Best is trial 15 with value: 0.9166666666666666.\n",
      "[I 2025-09-29 14:06:29,162] Trial 30 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09942257592556773, 'num_epochs': 225}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:06:40,187] Trial 31 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.0924217606564696, 'num_epochs': 226}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:07:03,886] Trial 32 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09009865058920948, 'num_epochs': 297}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:07:24,567] Trial 33 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.0658315917861262, 'num_epochs': 313}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:07:39,980] Trial 34 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09614079738298416, 'num_epochs': 383}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:08:00,025] Trial 35 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.09551596703817213, 'num_epochs': 433}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:08:02,797] Trial 36 pruned. \n",
      "[I 2025-09-29 14:08:20,072] Trial 37 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.0993126179406564, 'num_epochs': 300}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:08:21,272] Trial 38 pruned. \n",
      "[I 2025-09-29 14:08:53,058] Trial 39 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.024915983377090306, 'num_epochs': 386}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:08:55,157] Trial 40 pruned. \n",
      "[I 2025-09-29 14:09:14,468] Trial 41 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08976793687489172, 'num_epochs': 293}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:09:34,066] Trial 42 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09572759115972732, 'num_epochs': 349}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:09:46,099] Trial 43 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.05729500856861851, 'num_epochs': 272}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:10:06,039] Trial 44 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.034069873072567744, 'num_epochs': 307}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:10:38,502] Trial 45 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.05237536691161379, 'num_epochs': 498}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:10:40,824] Trial 46 pruned. \n",
      "[I 2025-09-29 14:10:42,416] Trial 47 pruned. \n",
      "[I 2025-09-29 14:10:46,575] Trial 48 pruned. \n",
      "[I 2025-09-29 14:10:48,738] Trial 49 pruned. \n",
      "[I 2025-09-29 14:10:50,897] Trial 50 pruned. \n",
      "[I 2025-09-29 14:11:24,070] Trial 51 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.0984731473598915, 'num_epochs': 419}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:11:48,582] Trial 52 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.04788556244453703, 'num_epochs': 357}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:11:58,800] Trial 53 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.0669593257680591, 'num_epochs': 221}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:12:00,955] Trial 54 pruned. \n",
      "[I 2025-09-29 14:12:03,354] Trial 55 pruned. \n",
      "[I 2025-09-29 14:12:11,773] Trial 56 pruned. \n",
      "[I 2025-09-29 14:12:14,783] Trial 57 pruned. \n",
      "[I 2025-09-29 14:12:17,014] Trial 58 pruned. \n",
      "[I 2025-09-29 14:12:48,036] Trial 59 finished with value: 0.875 and parameters: {'batch_size_train': 64, 'lr': 0.026390243236358215, 'num_epochs': 392}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:12:59,960] Trial 60 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.06862391880673208, 'num_epochs': 209}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:13:17,807] Trial 61 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09616660855987089, 'num_epochs': 290}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:13:38,463] Trial 62 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06825349601357486, 'num_epochs': 313}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:13:40,017] Trial 63 pruned. \n",
      "[I 2025-09-29 14:13:41,719] Trial 64 pruned. \n",
      "[I 2025-09-29 14:13:58,469] Trial 65 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.0743952471729027, 'num_epochs': 259}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:14:21,461] Trial 66 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.04426024487465408, 'num_epochs': 368}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:14:24,233] Trial 67 pruned. \n",
      "[I 2025-09-29 14:14:26,171] Trial 68 pruned. \n",
      "[I 2025-09-29 14:14:29,642] Trial 69 pruned. \n",
      "[I 2025-09-29 14:14:37,674] Trial 70 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09916017928782225, 'num_epochs': 149}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:14:55,669] Trial 71 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09943059251754119, 'num_epochs': 377}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:15:17,880] Trial 72 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.0748667993398454, 'num_epochs': 338}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:15:36,527] Trial 73 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.0571526077203361, 'num_epochs': 351}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:15:37,902] Trial 74 pruned. \n",
      "[I 2025-09-29 14:15:57,218] Trial 75 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.07949865939883284, 'num_epochs': 318}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:15:58,599] Trial 76 pruned. \n",
      "[I 2025-09-29 14:16:00,845] Trial 77 pruned. \n",
      "[I 2025-09-29 14:16:02,806] Trial 78 pruned. \n",
      "[I 2025-09-29 14:16:04,291] Trial 79 pruned. \n",
      "[I 2025-09-29 14:16:06,339] Trial 80 pruned. \n",
      "[I 2025-09-29 14:16:20,395] Trial 81 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.054056125628662945, 'num_epochs': 272}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:16:36,480] Trial 82 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08386161628776223, 'num_epochs': 286}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:16:46,514] Trial 83 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06036827592010667, 'num_epochs': 262}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:16:56,241] Trial 84 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.07966056323138705, 'num_epochs': 192}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:17:25,375] Trial 85 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.048711035128386225, 'num_epochs': 437}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:17:38,523] Trial 86 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.060840429703641515, 'num_epochs': 213}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:17:42,907] Trial 87 pruned. \n",
      "[I 2025-09-29 14:17:44,968] Trial 88 pruned. \n",
      "[I 2025-09-29 14:17:51,624] Trial 89 pruned. \n",
      "[I 2025-09-29 14:18:15,625] Trial 90 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.039657213335390046, 'num_epochs': 383}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:18:39,028] Trial 91 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.05279544014668584, 'num_epochs': 478}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:18:58,215] Trial 92 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09986002710908223, 'num_epochs': 455}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:18:59,141] Trial 93 pruned. \n",
      "[I 2025-09-29 14:19:33,329] Trial 94 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.07800380530182442, 'num_epochs': 488}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:20:05,478] Trial 95 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06503985285161891, 'num_epochs': 304}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:20:19,432] Trial 96 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 16, 'lr': 0.028087850127340868, 'num_epochs': 204}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:20:20,634] Trial 97 pruned. \n",
      "[I 2025-09-29 14:20:36,266] Trial 98 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 64, 'lr': 0.06970914960114241, 'num_epochs': 281}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:20:56,349] Trial 99 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.038863820720686976, 'num_epochs': 253}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:21:28,738] Trial 100 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08420523866196042, 'num_epochs': 432}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:22:07,360] Trial 101 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.09901861584549157, 'num_epochs': 500}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:22:34,548] Trial 102 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.0628030018286808, 'num_epochs': 400}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:23:01,838] Trial 103 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.05026419474542021, 'num_epochs': 416}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:23:21,726] Trial 104 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08408145724407098, 'num_epochs': 371}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:23:24,695] Trial 105 pruned. \n",
      "[I 2025-09-29 14:23:53,699] Trial 106 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.04380006912127152, 'num_epochs': 426}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:24:34,761] Trial 107 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.08738898144112364, 'num_epochs': 340}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:25:26,931] Trial 108 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.057099970505773194, 'num_epochs': 363}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:25:29,475] Trial 109 pruned. \n",
      "[I 2025-09-29 14:25:42,059] Trial 110 pruned. \n",
      "[I 2025-09-29 14:26:03,080] Trial 111 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09550734595849891, 'num_epochs': 292}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:26:26,412] Trial 112 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.09844004489783732, 'num_epochs': 314}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:26:52,467] Trial 113 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.060445116448330324, 'num_epochs': 349}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:27:18,763] Trial 114 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.07359636788394135, 'num_epochs': 287}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:27:42,223] Trial 115 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.044533698032752325, 'num_epochs': 327}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:28:11,669] Trial 116 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.05292187008520845, 'num_epochs': 465}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:28:35,947] Trial 117 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 16, 'lr': 0.08613868743538311, 'num_epochs': 268}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:28:38,143] Trial 118 pruned. \n",
      "[I 2025-09-29 14:28:43,434] Trial 119 pruned. \n",
      "[I 2025-09-29 14:28:44,749] Trial 120 pruned. \n",
      "[I 2025-09-29 14:29:04,040] Trial 121 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06491690201601631, 'num_epochs': 310}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:29:25,204] Trial 122 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08504116142076472, 'num_epochs': 316}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:29:44,929] Trial 123 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09731296313186295, 'num_epochs': 294}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:30:10,355] Trial 124 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.05372909520835903, 'num_epochs': 333}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:30:25,514] Trial 125 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.07257384058062863, 'num_epochs': 279}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:30:50,577] Trial 126 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 64, 'lr': 0.033728002144213835, 'num_epochs': 407}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:31:12,941] Trial 127 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.04307070861316113, 'num_epochs': 358}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:31:31,475] Trial 128 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.05851167454409871, 'num_epochs': 323}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:31:52,771] Trial 129 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.07927333857261025, 'num_epochs': 303}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:32:08,137] Trial 130 pruned. \n",
      "[I 2025-09-29 14:32:36,396] Trial 131 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.04703883091259663, 'num_epochs': 369}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:33:04,456] Trial 132 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06570683113234009, 'num_epochs': 397}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:33:19,520] Trial 133 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.07885956931864281, 'num_epochs': 377}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:33:43,677] Trial 134 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.03751486648511839, 'num_epochs': 365}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:33:45,983] Trial 135 pruned. \n",
      "[I 2025-09-29 14:34:11,757] Trial 136 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.05144706012608694, 'num_epochs': 352}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:34:30,518] Trial 137 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09960656044515617, 'num_epochs': 263}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:34:54,568] Trial 138 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.0665939219473934, 'num_epochs': 334}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:34:56,539] Trial 139 pruned. \n",
      "[I 2025-09-29 14:34:58,663] Trial 140 pruned. \n",
      "[I 2025-09-29 14:35:07,554] Trial 141 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08371674594454295, 'num_epochs': 138}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:35:17,976] Trial 142 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.09656870530138606, 'num_epochs': 151}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:35:47,034] Trial 143 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.05894536534733975, 'num_epochs': 382}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:35:59,848] Trial 144 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.07423175023308001, 'num_epochs': 186}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:36:07,646] Trial 145 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.046400799768349654, 'num_epochs': 110}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:36:12,858] Trial 146 pruned. \n",
      "[I 2025-09-29 14:36:44,584] Trial 147 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.059141609624266844, 'num_epochs': 420}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:37:03,742] Trial 148 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.07128161206287001, 'num_epochs': 274}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:37:17,001] Trial 149 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 16, 'lr': 0.03853219228405314, 'num_epochs': 171}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:37:18,665] Trial 150 pruned. \n",
      "[I 2025-09-29 14:37:22,632] Trial 151 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.09934761593648948, 'num_epochs': 64}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:37:24,864] Trial 152 pruned. \n",
      "[I 2025-09-29 14:37:53,614] Trial 153 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09803967725160269, 'num_epochs': 387}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:38:16,199] Trial 154 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06655294574567834, 'num_epochs': 320}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:38:41,291] Trial 155 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.09902752710229638, 'num_epochs': 354}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:39:08,762] Trial 156 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.0518383566313567, 'num_epochs': 375}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:39:13,848] Trial 157 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 64, 'lr': 0.07498734929102902, 'num_epochs': 86}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:39:44,893] Trial 158 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.05899188343488941, 'num_epochs': 407}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:40:08,486] Trial 159 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 1024, 'lr': 0.07934492124776882, 'num_epochs': 360}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:40:29,076] Trial 160 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06486545763909157, 'num_epochs': 286}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:40:55,661] Trial 161 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08384101793793931, 'num_epochs': 347}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:41:19,564] Trial 162 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09881511710065015, 'num_epochs': 330}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:41:21,726] Trial 163 pruned. \n",
      "[I 2025-09-29 14:41:43,798] Trial 164 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.07511276239749035, 'num_epochs': 296}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:42:06,488] Trial 165 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.04968125052398417, 'num_epochs': 316}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:42:34,594] Trial 166 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.06452897348982707, 'num_epochs': 368}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:42:58,518] Trial 167 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.08046503779972862, 'num_epochs': 336}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:43:09,372] Trial 168 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.05497062248183468, 'num_epochs': 161}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:43:34,169] Trial 169 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09980841790148096, 'num_epochs': 342}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:43:36,246] Trial 170 pruned. \n",
      "[I 2025-09-29 14:44:02,165] Trial 171 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06786965357403014, 'num_epochs': 353}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:44:30,575] Trial 172 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08296118358233533, 'num_epochs': 379}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:44:58,031] Trial 173 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.057879408279306356, 'num_epochs': 363}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:45:22,177] Trial 174 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.07259950965242429, 'num_epochs': 326}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:45:57,886] Trial 175 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08371685927412024, 'num_epochs': 458}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:46:35,371] Trial 176 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.05388997191108775, 'num_epochs': 472}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:46:56,808] Trial 177 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.040574700140731494, 'num_epochs': 302}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:47:02,505] Trial 178 pruned. \n",
      "[I 2025-09-29 14:47:24,253] Trial 179 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06087523659335985, 'num_epochs': 286}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:47:33,477] Trial 180 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.0986963012126657, 'num_epochs': 135}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:47:56,638] Trial 181 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08271327767667785, 'num_epochs': 313}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:47:58,674] Trial 182 pruned. \n",
      "[I 2025-09-29 14:48:28,522] Trial 183 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08486154870761445, 'num_epochs': 390}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:48:51,634] Trial 184 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06884690282895327, 'num_epochs': 339}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:49:15,528] Trial 185 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.04872425265721411, 'num_epochs': 320}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:50:00,323] Trial 186 finished with value: 0.875 and parameters: {'batch_size_train': 16, 'lr': 0.08431227107059162, 'num_epochs': 498}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:50:22,282] Trial 187 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.0616154713614885, 'num_epochs': 305}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:50:37,994] Trial 188 finished with value: 0.875 and parameters: {'batch_size_train': 64, 'lr': 0.09826168534833879, 'num_epochs': 237}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:50:50,640] Trial 189 pruned. \n",
      "[I 2025-09-29 14:51:11,865] Trial 190 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.054505628343903975, 'num_epochs': 295}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:51:32,165] Trial 191 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.08480072560194568, 'num_epochs': 277}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:51:51,122] Trial 192 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.046660318440555786, 'num_epochs': 268}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:52:06,864] Trial 193 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.06948318743701432, 'num_epochs': 228}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:52:27,815] Trial 194 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.05867125590620521, 'num_epochs': 287}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:52:29,968] Trial 195 pruned. \n",
      "[I 2025-09-29 14:52:48,676] Trial 196 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.09906493368047792, 'num_epochs': 260}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:53:15,056] Trial 197 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.03356086421717162, 'num_epochs': 353}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:53:16,839] Trial 198 pruned. \n",
      "[I 2025-09-29 14:53:43,714] Trial 199 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.04125406211867425, 'num_epochs': 360}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:54:04,520] Trial 200 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06856056194085546, 'num_epochs': 279}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:54:24,129] Trial 201 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.08545217966630764, 'num_epochs': 269}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:54:45,530] Trial 202 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08268691264434079, 'num_epochs': 290}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:55:08,943] Trial 203 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.0994434703847452, 'num_epochs': 300}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:55:37,318] Trial 204 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06056749205511937, 'num_epochs': 370}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:55:58,929] Trial 205 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.07220412652998502, 'num_epochs': 282}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:56:17,550] Trial 206 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.052098237860880976, 'num_epochs': 252}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:56:47,828] Trial 207 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08214939271820212, 'num_epochs': 380}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:57:11,762] Trial 208 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.09954127568696754, 'num_epochs': 308}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:57:13,928] Trial 209 pruned. \n",
      "[I 2025-09-29 14:57:46,254] Trial 210 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06808599198563697, 'num_epochs': 402}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:58:05,061] Trial 211 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.059288397132878354, 'num_epochs': 264}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:58:25,232] Trial 212 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.08046647848202378, 'num_epochs': 271}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:58:27,579] Trial 213 pruned. \n",
      "[I 2025-09-29 14:58:49,276] Trial 214 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09979600287362622, 'num_epochs': 280}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:59:07,429] Trial 215 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06989183490798943, 'num_epochs': 256}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:59:31,815] Trial 216 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06152855484064127, 'num_epochs': 322}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 14:59:44,610] Trial 217 pruned. \n",
      "[I 2025-09-29 15:00:07,646] Trial 218 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.04800999475022155, 'num_epochs': 289}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:00:34,019] Trial 219 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08285366441043968, 'num_epochs': 343}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:00:55,197] Trial 220 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.067680331878026, 'num_epochs': 271}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:01:30,288] Trial 221 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.040567057524969065, 'num_epochs': 426}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:02:07,541] Trial 222 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.05131948081863412, 'num_epochs': 443}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:02:43,737] Trial 223 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08541885252194471, 'num_epochs': 486}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:02:47,565] Trial 224 pruned. \n",
      "[I 2025-09-29 15:03:22,977] Trial 225 finished with value: 0.875 and parameters: {'batch_size_train': 16, 'lr': 0.05923443309651105, 'num_epochs': 374}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:03:52,670] Trial 226 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09838678312106801, 'num_epochs': 388}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:04:14,149] Trial 227 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06987490986593502, 'num_epochs': 284}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:04:15,862] Trial 228 pruned. \n",
      "[I 2025-09-29 15:04:39,279] Trial 229 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.07576625661390732, 'num_epochs': 308}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:04:41,550] Trial 230 pruned. \n",
      "[I 2025-09-29 15:04:58,840] Trial 231 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.0594567704013809, 'num_epochs': 233}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:05:14,835] Trial 232 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.04606220314549614, 'num_epochs': 215}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:05:31,577] Trial 233 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.08495351355352186, 'num_epochs': 224}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:05:48,010] Trial 234 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 64, 'lr': 0.06827943142236283, 'num_epochs': 244}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:06:02,927] Trial 235 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09837578632897954, 'num_epochs': 205}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:06:19,186] Trial 236 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.059104021882360414, 'num_epochs': 217}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:06:46,681] Trial 237 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.0756834232104173, 'num_epochs': 364}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:07:09,721] Trial 238 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.046581140889115955, 'num_epochs': 298}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:07:37,424] Trial 239 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08525791084146704, 'num_epochs': 354}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:07:51,135] Trial 240 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.054313463425207154, 'num_epochs': 191}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:08:21,944] Trial 241 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.036220347807555585, 'num_epochs': 394}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:08:25,706] Trial 242 pruned. \n",
      "[I 2025-09-29 15:08:27,901] Trial 243 pruned. \n",
      "[I 2025-09-29 15:08:56,140] Trial 244 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.07198332467264579, 'num_epochs': 368}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:09:27,878] Trial 245 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08475197218845235, 'num_epochs': 396}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:09:53,590] Trial 246 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.09886652671310518, 'num_epochs': 336}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:10:24,284] Trial 247 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.06196975321972602, 'num_epochs': 381}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:10:33,286] Trial 248 finished with value: 0.8333333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.050240580860686015, 'num_epochs': 123}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:10:53,968] Trial 249 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.07420442538418755, 'num_epochs': 277}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:11:15,824] Trial 250 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09974407154831615, 'num_epochs': 293}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:11:50,608] Trial 251 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.06310421265725939, 'num_epochs': 430}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:12:10,948] Trial 252 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.08400098653214769, 'num_epochs': 264}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:12:22,253] Trial 253 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.042230683862513635, 'num_epochs': 159}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:12:43,128] Trial 254 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 128, 'lr': 0.0531818633063748, 'num_epochs': 316}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:13:15,165] Trial 255 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.07100976385263781, 'num_epochs': 405}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:13:43,077] Trial 256 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08369103635320453, 'num_epochs': 358}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:13:45,190] Trial 257 pruned. \n",
      "[I 2025-09-29 15:13:47,468] Trial 258 pruned. \n",
      "[I 2025-09-29 15:14:26,721] Trial 259 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.08541125854735364, 'num_epochs': 476}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:14:52,154] Trial 260 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.07157576766967266, 'num_epochs': 326}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:14:57,690] Trial 261 finished with value: 0.4583333333333333 and parameters: {'batch_size_train': 32, 'lr': 0.00043207779556098894, 'num_epochs': 82}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:15:28,875] Trial 262 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.05014038231660779, 'num_epochs': 386}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:15:57,745] Trial 263 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 16, 'lr': 0.08623431102117682, 'num_epochs': 303}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:15:59,753] Trial 264 pruned. \n",
      "[I 2025-09-29 15:16:01,938] Trial 265 pruned. \n",
      "[I 2025-09-29 15:16:07,728] Trial 266 pruned. \n",
      "[I 2025-09-29 15:16:37,517] Trial 267 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.0611911615325083, 'num_epochs': 370}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:16:55,949] Trial 268 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 64, 'lr': 0.04141196461384083, 'num_epochs': 257}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:17:30,713] Trial 269 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.07285473308869127, 'num_epochs': 420}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:17:48,427] Trial 270 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.054982475295406855, 'num_epochs': 231}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:17:50,493] Trial 271 pruned. \n",
      "[I 2025-09-29 15:18:16,632] Trial 272 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09972495563813549, 'num_epochs': 342}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:18:36,004] Trial 273 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.07202653042296087, 'num_epochs': 244}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:19:05,799] Trial 274 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.030473348009324257, 'num_epochs': 378}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:19:34,621] Trial 275 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08377080104207099, 'num_epochs': 363}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:19:36,677] Trial 276 pruned. \n",
      "[I 2025-09-29 15:19:38,980] Trial 277 pruned. \n",
      "[I 2025-09-29 15:20:01,626] Trial 278 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.04514428754254937, 'num_epochs': 297}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:20:23,227] Trial 279 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.09993215056471468, 'num_epochs': 285}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:20:25,630] Trial 280 pruned. \n",
      "[I 2025-09-29 15:20:27,664] Trial 281 pruned. \n",
      "[I 2025-09-29 15:20:52,179] Trial 282 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.0763443599384682, 'num_epochs': 330}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:21:34,593] Trial 283 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.055519564097713504, 'num_epochs': 489}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:22:07,192] Trial 284 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06724558384372956, 'num_epochs': 410}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:22:34,640] Trial 285 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08318464247452706, 'num_epochs': 349}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:22:51,698] Trial 286 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.036423297113399596, 'num_epochs': 224}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:23:14,872] Trial 287 finished with value: 0.875 and parameters: {'batch_size_train': 32, 'lr': 0.04898979836285337, 'num_epochs': 321}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:23:27,681] Trial 288 pruned. \n",
      "[I 2025-09-29 15:23:59,311] Trial 289 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08621401267492554, 'num_epochs': 392}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:24:01,265] Trial 290 pruned. \n",
      "[I 2025-09-29 15:24:29,658] Trial 291 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.05621213953291075, 'num_epochs': 357}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:24:42,587] Trial 292 pruned. \n",
      "[I 2025-09-29 15:25:19,378] Trial 293 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 16, 'lr': 0.07189716560568074, 'num_epochs': 398}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:25:42,493] Trial 294 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08190050882972555, 'num_epochs': 288}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:26:07,281] Trial 295 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.04722885869274877, 'num_epochs': 337}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:26:10,314] Trial 296 pruned. \n",
      "[I 2025-09-29 15:26:17,643] Trial 297 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08469415227165841, 'num_epochs': 101}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:26:41,685] Trial 298 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.038142211476731136, 'num_epochs': 250}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:26:44,122] Trial 299 pruned. \n",
      "[I 2025-09-29 15:26:45,957] Trial 300 pruned. \n",
      "[I 2025-09-29 15:26:59,344] Trial 301 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.07179802546660334, 'num_epochs': 274}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:27:10,385] Trial 302 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.05669740429479497, 'num_epochs': 238}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:27:26,902] Trial 303 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09862671341672531, 'num_epochs': 385}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:27:27,969] Trial 304 pruned. \n",
      "[I 2025-09-29 15:27:46,491] Trial 305 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.04472909035910257, 'num_epochs': 366}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:28:00,678] Trial 306 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08504088448166926, 'num_epochs': 302}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:28:19,985] Trial 307 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.09986477809070755, 'num_epochs': 466}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:28:27,683] Trial 308 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06423325407840606, 'num_epochs': 291}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:28:31,869] Trial 309 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.053664481327173684, 'num_epochs': 128}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:28:37,553] Trial 310 pruned. \n",
      "[I 2025-09-29 15:28:48,067] Trial 311 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08303627062379247, 'num_epochs': 379}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:28:54,312] Trial 312 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.0636879992578176, 'num_epochs': 259}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:28:55,079] Trial 313 pruned. \n",
      "[I 2025-09-29 15:29:02,821] Trial 314 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.042054923431489255, 'num_epochs': 317}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:29:07,561] Trial 315 pruned. \n",
      "[I 2025-09-29 15:29:09,087] Trial 316 pruned. \n",
      "[I 2025-09-29 15:29:09,850] Trial 317 pruned. \n",
      "[I 2025-09-29 15:29:17,732] Trial 318 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06758281767400466, 'num_epochs': 302}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:29:18,633] Trial 319 pruned. \n",
      "[I 2025-09-29 15:29:30,380] Trial 320 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.09867640725280637, 'num_epochs': 453}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:29:47,838] Trial 321 finished with value: 0.875 and parameters: {'batch_size_train': 16, 'lr': 0.07787353985080912, 'num_epochs': 401}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:29:58,926] Trial 322 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.06282944742254308, 'num_epochs': 332}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:30:23,297] Trial 323 finished with value: 0.9166666666666666 and parameters: {'batch_size_train': 32, 'lr': 0.0468359739783805, 'num_epochs': 376}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:30:39,230] Trial 324 pruned. \n",
      "[I 2025-09-29 15:30:57,845] Trial 325 finished with value: 0.9583333333333334 and parameters: {'batch_size_train': 32, 'lr': 0.08550052452176815, 'num_epochs': 216}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[I 2025-09-29 15:31:15,048] Trial 326 finished with value: 0.875 and parameters: {'batch_size_train': 64, 'lr': 0.07103969335251015, 'num_epochs': 314}. Best is trial 30 with value: 0.9583333333333334.\n",
      "[W 2025-09-29 15:31:24,816] Trial 327 failed with parameters: {'batch_size_train': 32, 'lr': 0.09931651732007894, 'num_epochs': 273} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\LorenzoColpani\\AppData\\Local\\Temp\\ipykernel_24712\\1274523093.py\", line 36, in objective\n",
      "    if trial.should_prune():\n",
      "       ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\trial\\_trial.py\", line 539, in should_prune\n",
      "    return self.study.pruner.prune(self.study, trial)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\pruners\\_percentile.py\", line 173, in prune\n",
      "    completed_trials = study.get_trials(deepcopy=False, states=(TrialState.COMPLETE,))\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\study\\study.py\", line 267, in get_trials\n",
      "    return self._get_trials(deepcopy, states, use_cache=False)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\study\\study.py\", line 287, in _get_trials\n",
      "    return self._storage.get_all_trials(self._study_id, deepcopy=deepcopy, states=states)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\storages\\_cached_storage.py\", line 219, in get_all_trials\n",
      "    self._read_trials_from_remote_storage(study_id)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\storages\\_cached_storage.py\", line 240, in _read_trials_from_remote_storage\n",
      "    trials = self._backend._get_trials(\n",
      "        study_id,\n",
      "    ...<2 lines>...\n",
      "        trial_id_greater_than=study.last_finished_trial_id,\n",
      "    )\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py\", line 838, in _get_trials\n",
      "    trial_models = _query.order_by(models.TrialModel.trial_id).all()\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\query.py\", line 2704, in all\n",
      "    return self._iter().all()  # type: ignore\n",
      "           ~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\result.py\", line 1774, in all\n",
      "    return self._allrows()\n",
      "           ~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\result.py\", line 548, in _allrows\n",
      "    rows = self._fetchall_impl()\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\result.py\", line 1681, in _fetchall_impl\n",
      "    return self._real_result._fetchall_impl()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\result.py\", line 2275, in _fetchall_impl\n",
      "    return list(self.iterator)\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\loading.py\", line 247, in chunks\n",
      "    post_load.invoke(context, path)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\loading.py\", line 1564, in invoke\n",
      "    loader(\n",
      "    ~~~~~~^\n",
      "        effective_context, path, states, self.load_keys, *arg, **kw\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\strategies.py\", line 3338, in _load_for_path\n",
      "    self._load_via_parent(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^\n",
      "        our_states, query_info, q, context, execution_options\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\strategies.py\", line 3414, in _load_via_parent\n",
      "    context.session.execute(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        q,\n",
      "        ^^\n",
      "        params={\"primary_keys\": primary_keys},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        execution_options=execution_options,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ).unique(),\n",
      "    ^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\session.py\", line 2365, in execute\n",
      "    return self._execute_internal(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        statement,\n",
      "        ^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        _add_event=_add_event,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\session.py\", line 2251, in _execute_internal\n",
      "    result: Result[Any] = compile_state_cls.orm_execute_statement(\n",
      "                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self,\n",
      "        ^^^^^\n",
      "    ...<4 lines>...\n",
      "        conn,\n",
      "        ^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\context.py\", line 306, in orm_execute_statement\n",
      "    result = conn.execute(\n",
      "        statement, params or {}, execution_options=execution_options\n",
      "    )\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1419, in execute\n",
      "    return meth(\n",
      "        self,\n",
      "        distilled_parameters,\n",
      "        execution_options or NO_OPTIONS,\n",
      "    )\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py\", line 526, in _execute_on_connection\n",
      "    return connection._execute_clauseelement(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, distilled_params, execution_options\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1641, in _execute_clauseelement\n",
      "    ret = self._execute_context(\n",
      "        dialect,\n",
      "    ...<8 lines>...\n",
      "        cache_hit=cache_hit,\n",
      "    )\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1846, in _execute_context\n",
      "    return self._exec_single_context(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        dialect, context, statement, parameters\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1986, in _exec_single_context\n",
      "    self._handle_dbapi_exception(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        e, str_statement, effective_parameters, cursor, context\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 2358, in _handle_dbapi_exception\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1967, in _exec_single_context\n",
      "    self.dialect.do_execute(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        cursor, str_statement, effective_parameters, context\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 951, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-09-29 15:31:25,140] Trial 327 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Start the optimization. Optuna will run the objective function 100 times.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     33\u001b[39m     validation_accuracy = correct / total\n\u001b[32m     34\u001b[39m     trial.report(validation_accuracy, epoch)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshould_prune\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m optuna.TrialPruned()\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m validation_accuracy\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\trial\\_trial.py:539\u001b[39m, in \u001b[36mTrial.should_prune\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    534\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    535\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTrial.should_prune is not supported for multi-objective optimization.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    536\u001b[39m     )\n\u001b[32m    538\u001b[39m trial = \u001b[38;5;28mself\u001b[39m._get_latest_trial()\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpruner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprune\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\pruners\\_percentile.py:173\u001b[39m, in \u001b[36mPercentilePruner.prune\u001b[39m\u001b[34m(self, study, trial)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprune\u001b[39m(\u001b[38;5;28mself\u001b[39m, study: \u001b[33m\"\u001b[39m\u001b[33moptuna.study.Study\u001b[39m\u001b[33m\"\u001b[39m, trial: \u001b[33m\"\u001b[39m\u001b[33moptuna.trial.FrozenTrial\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     completed_trials = \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTrialState\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCOMPLETE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m     n_trials = \u001b[38;5;28mlen\u001b[39m(completed_trials)\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_trials == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:267\u001b[39m, in \u001b[36mStudy.get_trials\u001b[39m\u001b[34m(self, deepcopy, states)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_trials\u001b[39m(\n\u001b[32m    228\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    229\u001b[39m     deepcopy: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    230\u001b[39m     states: Container[TrialState] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    231\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[FrozenTrial]:\n\u001b[32m    232\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return all trials in the study.\u001b[39;00m\n\u001b[32m    233\u001b[39m \n\u001b[32m    234\u001b[39m \u001b[33;03m    The returned trials are ordered by trial number.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    265\u001b[39m \u001b[33;03m        A list of :class:`~optuna.trial.FrozenTrial` objects.\u001b[39;00m\n\u001b[32m    266\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:287\u001b[39m, in \u001b[36mStudy._get_trials\u001b[39m\u001b[34m(self, deepcopy, states, use_cache)\u001b[39m\n\u001b[32m    284\u001b[39m         filtered_trials = trials\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m copy.deepcopy(filtered_trials) \u001b[38;5;28;01mif\u001b[39;00m deepcopy \u001b[38;5;28;01melse\u001b[39;00m filtered_trials\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_storage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_all_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_study_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\storages\\_cached_storage.py:219\u001b[39m, in \u001b[36m_CachedStorage.get_all_trials\u001b[39m\u001b[34m(self, study_id, deepcopy, states)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_all_trials\u001b[39m(\n\u001b[32m    214\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    215\u001b[39m     study_id: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m    216\u001b[39m     deepcopy: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    217\u001b[39m     states: Container[TrialState] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    218\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[FrozenTrial]:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_trials_from_remote_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m    222\u001b[39m         study = \u001b[38;5;28mself\u001b[39m._studies[study_id]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\storages\\_cached_storage.py:240\u001b[39m, in \u001b[36m_CachedStorage._read_trials_from_remote_storage\u001b[39m\u001b[34m(self, study_id)\u001b[39m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28mself\u001b[39m._studies[study_id] = _StudyInfo()\n\u001b[32m    239\u001b[39m study = \u001b[38;5;28mself\u001b[39m._studies[study_id]\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m trials = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_trials\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mincluded_trial_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43munfinished_trial_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrial_id_greater_than\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlast_finished_trial_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trials:\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py:838\u001b[39m, in \u001b[36mRDBStorage._get_trials\u001b[39m\u001b[34m(self, study_id, states, included_trial_ids, trial_id_greater_than)\u001b[39m\n\u001b[32m    836\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    837\u001b[39m         _query = query\n\u001b[32m--> \u001b[39m\u001b[32m838\u001b[39m     trial_models = \u001b[43m_query\u001b[49m\u001b[43m.\u001b[49m\u001b[43morder_by\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTrialModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrial_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m sqlalchemy_exc.OperationalError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    840\u001b[39m     \u001b[38;5;66;03m# Likely exceeding the number of maximum allowed variables using IN.\u001b[39;00m\n\u001b[32m    841\u001b[39m     \u001b[38;5;66;03m# This number differ between database dialects. For SQLite for instance, see\u001b[39;00m\n\u001b[32m    842\u001b[39m     \u001b[38;5;66;03m# https://www.sqlite.org/limits.html and the section describing\u001b[39;00m\n\u001b[32m    843\u001b[39m     \u001b[38;5;66;03m# SQLITE_MAX_VARIABLE_NUMBER.\u001b[39;00m\n\u001b[32m    845\u001b[39m     _logger.warning(\n\u001b[32m    846\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCaught an error from sqlalchemy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. Falling back to a slower alternative. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    847\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m    848\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\query.py:2704\u001b[39m, in \u001b[36mQuery.all\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2682\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mall\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[_T]:\n\u001b[32m   2683\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the results represented by this :class:`_query.Query`\u001b[39;00m\n\u001b[32m   2684\u001b[39m \u001b[33;03m    as a list.\u001b[39;00m\n\u001b[32m   2685\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2702\u001b[39m \u001b[33;03m        :meth:`_engine.Result.scalars` - v2 comparable method.\u001b[39;00m\n\u001b[32m   2703\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2704\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\result.py:1774\u001b[39m, in \u001b[36mScalarResult.all\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1766\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mall\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Sequence[_R]:\n\u001b[32m   1767\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return all scalar values in a sequence.\u001b[39;00m\n\u001b[32m   1768\u001b[39m \n\u001b[32m   1769\u001b[39m \u001b[33;03m    Equivalent to :meth:`_engine.Result.all` except that\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1772\u001b[39m \n\u001b[32m   1773\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_allrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\result.py:548\u001b[39m, in \u001b[36mResultInternal._allrows\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    544\u001b[39m post_creational_filter = \u001b[38;5;28mself\u001b[39m._post_creational_filter\n\u001b[32m    546\u001b[39m make_row = \u001b[38;5;28mself\u001b[39m._row_getter\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m rows = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fetchall_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    549\u001b[39m made_rows: List[_InterimRowType[_R]]\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m make_row:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\result.py:1681\u001b[39m, in \u001b[36mFilterResult._fetchall_impl\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1680\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fetchall_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[_InterimRowType[Row[Any]]]:\n\u001b[32m-> \u001b[39m\u001b[32m1681\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_real_result\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fetchall_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\result.py:2275\u001b[39m, in \u001b[36mIteratorResult._fetchall_impl\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2273\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_hard_closed()\n\u001b[32m   2274\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2275\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2276\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2277\u001b[39m     \u001b[38;5;28mself\u001b[39m._soft_close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\loading.py:247\u001b[39m, in \u001b[36minstances.<locals>.chunks\u001b[39m\u001b[34m(size)\u001b[39m\n\u001b[32m    245\u001b[39m     context.post_load_paths.clear()\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m path, post_load \u001b[38;5;129;01min\u001b[39;00m post_loads:\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m         \u001b[43mpost_load\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m yield_per:\n\u001b[32m    250\u001b[39m     context.post_load_paths.clear()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\loading.py:1564\u001b[39m, in \u001b[36mPostLoad.invoke\u001b[39m\u001b[34m(self, context, path)\u001b[39m\n\u001b[32m   1558\u001b[39m     states = [\n\u001b[32m   1559\u001b[39m         (state, overwrite)\n\u001b[32m   1560\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m state, overwrite \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.states.items()\n\u001b[32m   1561\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m state.manager.mapper.isa(limit_to_mapper)\n\u001b[32m   1562\u001b[39m     ]\n\u001b[32m   1563\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m states:\n\u001b[32m-> \u001b[39m\u001b[32m1564\u001b[39m         \u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[43m            \u001b[49m\u001b[43meffective_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\n\u001b[32m   1566\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1567\u001b[39m \u001b[38;5;28mself\u001b[39m.states.clear()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\strategies.py:3338\u001b[39m, in \u001b[36mSelectInLoader._load_for_path\u001b[39m\u001b[34m(self, context, path, states, load_only, effective_entity, loadopt, recursion_depth, execution_options)\u001b[39m\n\u001b[32m   3329\u001b[39m     \u001b[38;5;28mself\u001b[39m._load_via_child(\n\u001b[32m   3330\u001b[39m         our_states,\n\u001b[32m   3331\u001b[39m         none_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3335\u001b[39m         execution_options,\n\u001b[32m   3336\u001b[39m     )\n\u001b[32m   3337\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3338\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_via_parent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3339\u001b[39m \u001b[43m        \u001b[49m\u001b[43mour_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[32m   3340\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\strategies.py:3414\u001b[39m, in \u001b[36mSelectInLoader._load_via_parent\u001b[39m\u001b[34m(self, our_states, query_info, q, context, execution_options)\u001b[39m\n\u001b[32m   3407\u001b[39m primary_keys = [\n\u001b[32m   3408\u001b[39m     key[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m query_info.zero_idx \u001b[38;5;28;01melse\u001b[39;00m key\n\u001b[32m   3409\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, state, state_dict, overwrite \u001b[38;5;129;01min\u001b[39;00m chunk\n\u001b[32m   3410\u001b[39m ]\n\u001b[32m   3412\u001b[39m data = collections.defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[32m   3413\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m itertools.groupby(\n\u001b[32m-> \u001b[39m\u001b[32m3414\u001b[39m     \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3416\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprimary_keys\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimary_keys\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3418\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.unique(),\n\u001b[32m   3419\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m0\u001b[39m],\n\u001b[32m   3420\u001b[39m ):\n\u001b[32m   3421\u001b[39m     data[k].extend(vv[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m vv \u001b[38;5;129;01min\u001b[39;00m v)\n\u001b[32m   3423\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, state, state_dict, overwrite \u001b[38;5;129;01min\u001b[39;00m chunk:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:2365\u001b[39m, in \u001b[36mSession.execute\u001b[39m\u001b[34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event)\u001b[39m\n\u001b[32m   2305\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(\n\u001b[32m   2306\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2307\u001b[39m     statement: Executable,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2313\u001b[39m     _add_event: Optional[Any] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2314\u001b[39m ) -> Result[Any]:\n\u001b[32m   2315\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Execute a SQL expression construct.\u001b[39;00m\n\u001b[32m   2316\u001b[39m \n\u001b[32m   2317\u001b[39m \u001b[33;03m    Returns a :class:`_engine.Result` object representing\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2363\u001b[39m \n\u001b[32m   2364\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2366\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2367\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2368\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2369\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbind_arguments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbind_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2370\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_parent_execute_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_parent_execute_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2371\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_add_event\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_add_event\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2372\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:2251\u001b[39m, in \u001b[36mSession._execute_internal\u001b[39m\u001b[34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event, _scalar_result)\u001b[39m\n\u001b[32m   2246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m conn.scalar(\n\u001b[32m   2247\u001b[39m         statement, params \u001b[38;5;129;01mor\u001b[39;00m {}, execution_options=execution_options\n\u001b[32m   2248\u001b[39m     )\n\u001b[32m   2250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compile_state_cls:\n\u001b[32m-> \u001b[39m\u001b[32m2251\u001b[39m     result: Result[Any] = \u001b[43mcompile_state_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43morm_execute_statement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbind_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2258\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2259\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2260\u001b[39m     result = conn.execute(\n\u001b[32m   2261\u001b[39m         statement, params \u001b[38;5;129;01mor\u001b[39;00m {}, execution_options=execution_options\n\u001b[32m   2262\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\context.py:306\u001b[39m, in \u001b[36mAbstractORMCompileState.orm_execute_statement\u001b[39m\u001b[34m(cls, session, statement, params, execution_options, bind_arguments, conn)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34morm_execute_statement\u001b[39m(\n\u001b[32m    298\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    304\u001b[39m     conn,\n\u001b[32m    305\u001b[39m ) -> Result:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     result = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.orm_setup_cursor_result(\n\u001b[32m    310\u001b[39m         session,\n\u001b[32m    311\u001b[39m         statement,\n\u001b[32m   (...)\u001b[39m\u001b[32m    315\u001b[39m         result,\n\u001b[32m    316\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1419\u001b[39m, in \u001b[36mConnection.execute\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1418\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1420\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1423\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:526\u001b[39m, in \u001b[36mClauseElement._execute_on_connection\u001b[39m\u001b[34m(self, connection, distilled_params, execution_options)\u001b[39m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    530\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1641\u001b[39m, in \u001b[36mConnection._execute_clauseelement\u001b[39m\u001b[34m(self, elem, distilled_parameters, execution_options)\u001b[39m\n\u001b[32m   1629\u001b[39m compiled_cache: Optional[CompiledCacheType] = execution_options.get(\n\u001b[32m   1630\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompiled_cache\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.engine._compiled_cache\n\u001b[32m   1631\u001b[39m )\n\u001b[32m   1633\u001b[39m compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(\n\u001b[32m   1634\u001b[39m     dialect=dialect,\n\u001b[32m   1635\u001b[39m     compiled_cache=compiled_cache,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1639\u001b[39m     linting=\u001b[38;5;28mself\u001b[39m.dialect.compiler_linting | compiler.WARN_LINTING,\n\u001b[32m   1640\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1641\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1649\u001b[39m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1653\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[32m   1654\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_execute(\n\u001b[32m   1655\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1656\u001b[39m         elem,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1660\u001b[39m         ret,\n\u001b[32m   1661\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1846\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1844\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exec_insertmany_context(dialect, context)\n\u001b[32m   1845\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1846\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1986\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1983\u001b[39m     result = context._setup_result_proxy()\n\u001b[32m   1985\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1987\u001b[39m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2358\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception\u001b[39m\u001b[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[39m\n\u001b[32m   2356\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2357\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2358\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc_info[\u001b[32m1\u001b[39m].with_traceback(exc_info[\u001b[32m2\u001b[39m])\n\u001b[32m   2359\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2360\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._reentrant_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1967\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1965\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1967\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1969\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n\u001b[32m   1972\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_cursor_execute(\n\u001b[32m   1973\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1974\u001b[39m         cursor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1978\u001b[39m         context.executemany,\n\u001b[32m   1979\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:951\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Start the optimization. Optuna will run the objective function 100 times.\n",
    "study.optimize(objective, n_trials=1000, callbacks=[champion_callback])\n",
    "\n",
    "mlflow.log_params(study.best_params)\n",
    "mlflow.log_metric(\"best_mse\", study.best_value)\n",
    "mlflow.log_metric(\"best_rmse\", math.sqrt(study.best_value))\n",
    "\n",
    "# Log tags\n",
    "mlflow.set_tags(\n",
    "    tags={\n",
    "        \"project\": \"Mean Teacher\",\n",
    "        \"optimizer_engine\": \"optuna\",\n",
    "        \"model_family\": \"pytorch\",\n",
    "        \"feature_set_version\": 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "artifact_path = \"model\"\n",
    "model = \n",
    "mlflow.pytorch.log_model(pytorch_model=model, name=artifact_path, input_example=train_data[0], model_format='ubj', metadata={'model_data_version': 1},)\n",
    "\n",
    "model_uri = mlflow.get_artifac_uri(artifact_path)\n",
    "\n",
    "loaded = mlflow.xgboost.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c70e04f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No trials are completed yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Print the best hyperparameters found\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m best_params = \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbest_params\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Print the best score achieved\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:120\u001b[39m, in \u001b[36mStudy.best_params\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbest_params\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    110\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return parameters of the best trial in the study.\u001b[39;00m\n\u001b[32m    111\u001b[39m \n\u001b[32m    112\u001b[39m \u001b[33;03m    .. note::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m \n\u001b[32m    118\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbest_trial\u001b[49m.params\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:156\u001b[39m, in \u001b[36mStudy.best_trial\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbest_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> FrozenTrial:\n\u001b[32m    141\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the best trial in the study.\u001b[39;00m\n\u001b[32m    142\u001b[39m \n\u001b[32m    143\u001b[39m \u001b[33;03m    .. note::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    154\u001b[39m \n\u001b[32m    155\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:308\u001b[39m, in \u001b[36mStudy._get_best_trial\u001b[39m\u001b[34m(self, deepcopy)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_multi_objective():\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    304\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    305\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    306\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m best_trial = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_storage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_study_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;66;03m# If the trial with the best value is infeasible, select the best trial from all feasible\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[38;5;66;03m# trials. Note that the behavior is undefined when constrained optimization without the\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[38;5;66;03m# violation value in the best-valued trial.\u001b[39;00m\n\u001b[32m    313\u001b[39m constraints = best_trial.system_attrs.get(_CONSTRAINTS_KEY)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LorenzoColpani\\Desktop\\repos\\semi_supervised_learning\\.venv\\Lib\\site-packages\\optuna\\storages\\_in_memory.py:252\u001b[39m, in \u001b[36mInMemoryStorage.get_best_trial\u001b[39m\u001b[34m(self, study_id)\u001b[39m\n\u001b[32m    249\u001b[39m best_trial_id = \u001b[38;5;28mself\u001b[39m._studies[study_id].best_trial_id\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best_trial_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo trials are completed yet.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._studies[study_id].directions) > \u001b[32m1\u001b[39m:\n\u001b[32m    254\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    255\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mBest trial can be obtained only for single-objective optimization.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    256\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: No trials are completed yet."
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters found\n",
    "best_params = study.best_params\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "# Print the best score achieved\n",
    "best_value = study.best_value\n",
    "print(f\"Best cross-validation accuracy: {best_value:.4f}\")\n",
    "\n",
    "# You can also get the best trial object itself for more details\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best trial number: {best_trial.number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163701f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1500], Loss: 1.1172\n",
      "Validation Loss: 1.0355\n",
      "Best model saved!\n",
      "Epoch [20/1500], Loss: 1.0169\n",
      "Validation Loss: 1.0044\n",
      "Best model saved!\n",
      "Epoch [30/1500], Loss: 0.8882\n",
      "Validation Loss: 0.9597\n",
      "Best model saved!\n",
      "Epoch [40/1500], Loss: 0.7929\n",
      "Validation Loss: 0.9178\n",
      "Best model saved!\n",
      "Epoch [50/1500], Loss: 0.8094\n",
      "Validation Loss: 0.8965\n",
      "Best model saved!\n",
      "Epoch [60/1500], Loss: 0.7888\n",
      "Validation Loss: 0.8818\n",
      "Best model saved!\n",
      "Epoch [70/1500], Loss: 0.6870\n",
      "Validation Loss: 0.8675\n",
      "Best model saved!\n",
      "Epoch [80/1500], Loss: 0.6844\n",
      "Validation Loss: 0.8736\n",
      "Epoch [90/1500], Loss: 0.6467\n",
      "Validation Loss: 0.8644\n",
      "Best model saved!\n",
      "Epoch [100/1500], Loss: 0.6725\n",
      "Validation Loss: 0.8553\n",
      "Best model saved!\n",
      "Epoch [110/1500], Loss: 0.6672\n",
      "Validation Loss: 0.8475\n",
      "Best model saved!\n",
      "Epoch [120/1500], Loss: 0.6257\n",
      "Validation Loss: 0.8262\n",
      "Best model saved!\n",
      "Epoch [130/1500], Loss: 0.6366\n",
      "Validation Loss: 0.8159\n",
      "Best model saved!\n",
      "Epoch [140/1500], Loss: 0.6313\n",
      "Validation Loss: 0.8030\n",
      "Best model saved!\n",
      "Epoch [150/1500], Loss: 0.6132\n",
      "Validation Loss: 0.7953\n",
      "Best model saved!\n",
      "Epoch [160/1500], Loss: 0.6794\n",
      "Validation Loss: 0.7856\n",
      "Best model saved!\n",
      "Epoch [170/1500], Loss: 0.6070\n",
      "Validation Loss: 0.7779\n",
      "Best model saved!\n",
      "Epoch [180/1500], Loss: 0.5196\n",
      "Validation Loss: 0.7791\n",
      "Epoch [190/1500], Loss: 0.6529\n",
      "Validation Loss: 0.7725\n",
      "Best model saved!\n",
      "Epoch [200/1500], Loss: 0.5797\n",
      "Validation Loss: 0.7668\n",
      "Best model saved!\n",
      "Epoch [210/1500], Loss: 0.6153\n",
      "Validation Loss: 0.7501\n",
      "Best model saved!\n",
      "Epoch [220/1500], Loss: 0.6216\n",
      "Validation Loss: 0.7357\n",
      "Best model saved!\n",
      "Epoch [230/1500], Loss: 0.4816\n",
      "Validation Loss: 0.7345\n",
      "Best model saved!\n",
      "Epoch [240/1500], Loss: 0.6106\n",
      "Validation Loss: 0.7362\n",
      "Epoch [250/1500], Loss: 0.5464\n",
      "Validation Loss: 0.7266\n",
      "Best model saved!\n",
      "Epoch [260/1500], Loss: 0.4758\n",
      "Validation Loss: 0.7115\n",
      "Best model saved!\n",
      "Epoch [270/1500], Loss: 0.5810\n",
      "Validation Loss: 0.6891\n",
      "Best model saved!\n",
      "Epoch [280/1500], Loss: 0.6358\n",
      "Validation Loss: 0.6963\n",
      "Epoch [290/1500], Loss: 0.5181\n",
      "Validation Loss: 0.6936\n",
      "Epoch [300/1500], Loss: 0.5876\n",
      "Validation Loss: 0.6833\n",
      "Best model saved!\n",
      "Epoch [310/1500], Loss: 0.5619\n",
      "Validation Loss: 0.6764\n",
      "Best model saved!\n",
      "Epoch [320/1500], Loss: 0.5657\n",
      "Validation Loss: 0.6756\n",
      "Best model saved!\n",
      "Epoch [330/1500], Loss: 0.4382\n",
      "Validation Loss: 0.6753\n",
      "Best model saved!\n",
      "Epoch [340/1500], Loss: 0.4448\n",
      "Validation Loss: 0.6778\n",
      "Epoch [350/1500], Loss: 0.5169\n",
      "Validation Loss: 0.6633\n",
      "Best model saved!\n",
      "Epoch [360/1500], Loss: 0.4219\n",
      "Validation Loss: 0.6493\n",
      "Best model saved!\n",
      "Epoch [370/1500], Loss: 0.4980\n",
      "Validation Loss: 0.6585\n",
      "Epoch [380/1500], Loss: 0.4948\n",
      "Validation Loss: 0.6597\n",
      "Epoch [390/1500], Loss: 0.4191\n",
      "Validation Loss: 0.6436\n",
      "Best model saved!\n",
      "Epoch [400/1500], Loss: 0.5032\n",
      "Validation Loss: 0.6457\n",
      "Epoch [410/1500], Loss: 0.4135\n",
      "Validation Loss: 0.6341\n",
      "Best model saved!\n",
      "Epoch [420/1500], Loss: 0.3575\n",
      "Validation Loss: 0.6391\n",
      "Epoch [430/1500], Loss: 0.4960\n",
      "Validation Loss: 0.6297\n",
      "Best model saved!\n",
      "Epoch [440/1500], Loss: 0.4021\n",
      "Validation Loss: 0.6205\n",
      "Best model saved!\n",
      "Epoch [450/1500], Loss: 0.4710\n",
      "Validation Loss: 0.6166\n",
      "Best model saved!\n",
      "Epoch [460/1500], Loss: 0.4596\n",
      "Validation Loss: 0.6178\n",
      "Epoch [470/1500], Loss: 0.4225\n",
      "Validation Loss: 0.6168\n",
      "Epoch [480/1500], Loss: 0.3170\n",
      "Validation Loss: 0.6077\n",
      "Best model saved!\n",
      "Epoch [490/1500], Loss: 0.3970\n",
      "Validation Loss: 0.6085\n",
      "Epoch [500/1500], Loss: 0.4632\n",
      "Validation Loss: 0.6092\n",
      "Epoch [510/1500], Loss: 0.3926\n",
      "Validation Loss: 0.5946\n",
      "Best model saved!\n",
      "Epoch [520/1500], Loss: 0.4412\n",
      "Validation Loss: 0.5947\n",
      "Epoch [530/1500], Loss: 0.4158\n",
      "Validation Loss: 0.6026\n",
      "Epoch [540/1500], Loss: 0.4067\n",
      "Validation Loss: 0.5872\n",
      "Best model saved!\n",
      "Epoch [550/1500], Loss: 0.4277\n",
      "Validation Loss: 0.5828\n",
      "Best model saved!\n",
      "Epoch [560/1500], Loss: 0.4077\n",
      "Validation Loss: 0.5853\n",
      "Epoch [570/1500], Loss: 0.3893\n",
      "Validation Loss: 0.5772\n",
      "Best model saved!\n",
      "Epoch [580/1500], Loss: 0.4510\n",
      "Validation Loss: 0.5733\n",
      "Best model saved!\n",
      "Epoch [590/1500], Loss: 0.3390\n",
      "Validation Loss: 0.5725\n",
      "Best model saved!\n",
      "Epoch [600/1500], Loss: 0.4859\n",
      "Validation Loss: 0.5745\n",
      "Epoch [610/1500], Loss: 0.3669\n",
      "Validation Loss: 0.5602\n",
      "Best model saved!\n",
      "Epoch [620/1500], Loss: 0.3890\n",
      "Validation Loss: 0.5685\n",
      "Epoch [630/1500], Loss: 0.3601\n",
      "Validation Loss: 0.5531\n",
      "Best model saved!\n",
      "Epoch [640/1500], Loss: 0.3481\n",
      "Validation Loss: 0.5585\n",
      "Epoch [650/1500], Loss: 0.3644\n",
      "Validation Loss: 0.5608\n",
      "Epoch [660/1500], Loss: 0.3455\n",
      "Validation Loss: 0.5400\n",
      "Best model saved!\n",
      "Epoch [670/1500], Loss: 0.4164\n",
      "Validation Loss: 0.5453\n",
      "Epoch [680/1500], Loss: 0.3455\n",
      "Validation Loss: 0.5566\n",
      "Epoch [690/1500], Loss: 0.3848\n",
      "Validation Loss: 0.5471\n",
      "Epoch [700/1500], Loss: 0.3764\n",
      "Validation Loss: 0.5308\n",
      "Best model saved!\n",
      "Epoch [710/1500], Loss: 0.3263\n",
      "Validation Loss: 0.5380\n",
      "Epoch [720/1500], Loss: 0.4014\n",
      "Validation Loss: 0.5385\n",
      "Epoch [730/1500], Loss: 0.3810\n",
      "Validation Loss: 0.5325\n",
      "Epoch [740/1500], Loss: 0.3679\n",
      "Validation Loss: 0.5318\n",
      "Epoch [750/1500], Loss: 0.3957\n",
      "Validation Loss: 0.5173\n",
      "Best model saved!\n",
      "Epoch [760/1500], Loss: 0.3436\n",
      "Validation Loss: 0.5204\n",
      "Epoch [770/1500], Loss: 0.3730\n",
      "Validation Loss: 0.5252\n",
      "Epoch [780/1500], Loss: 0.3193\n",
      "Validation Loss: 0.5233\n",
      "Epoch [790/1500], Loss: 0.3529\n",
      "Validation Loss: 0.5207\n",
      "Epoch [800/1500], Loss: 0.3441\n",
      "Validation Loss: 0.5128\n",
      "Best model saved!\n",
      "Epoch [810/1500], Loss: 0.4256\n",
      "Validation Loss: 0.5093\n",
      "Best model saved!\n",
      "Epoch [820/1500], Loss: 0.2728\n",
      "Validation Loss: 0.5096\n",
      "Epoch [830/1500], Loss: 0.3666\n",
      "Validation Loss: 0.5092\n",
      "Best model saved!\n",
      "Epoch [840/1500], Loss: 0.3258\n",
      "Validation Loss: 0.5130\n",
      "Epoch [850/1500], Loss: 0.3249\n",
      "Validation Loss: 0.5007\n",
      "Best model saved!\n",
      "Epoch [860/1500], Loss: 0.3396\n",
      "Validation Loss: 0.5036\n",
      "Epoch [870/1500], Loss: 0.3746\n",
      "Validation Loss: 0.4974\n",
      "Best model saved!\n",
      "Epoch [880/1500], Loss: 0.2773\n",
      "Validation Loss: 0.4931\n",
      "Best model saved!\n",
      "Epoch [890/1500], Loss: 0.3669\n",
      "Validation Loss: 0.4968\n",
      "Epoch [900/1500], Loss: 0.3307\n",
      "Validation Loss: 0.4874\n",
      "Best model saved!\n",
      "Epoch [910/1500], Loss: 0.2810\n",
      "Validation Loss: 0.4841\n",
      "Best model saved!\n",
      "Epoch [920/1500], Loss: 0.3416\n",
      "Validation Loss: 0.4818\n",
      "Best model saved!\n",
      "Epoch [930/1500], Loss: 0.3068\n",
      "Validation Loss: 0.4836\n",
      "Epoch [940/1500], Loss: 0.2827\n",
      "Validation Loss: 0.4728\n",
      "Best model saved!\n",
      "Epoch [950/1500], Loss: 0.3211\n",
      "Validation Loss: 0.4813\n",
      "Epoch [960/1500], Loss: 0.3569\n",
      "Validation Loss: 0.4805\n",
      "Epoch [970/1500], Loss: 0.3495\n",
      "Validation Loss: 0.4741\n",
      "Epoch [980/1500], Loss: 0.2894\n",
      "Validation Loss: 0.4716\n",
      "Best model saved!\n",
      "Epoch [990/1500], Loss: 0.2836\n",
      "Validation Loss: 0.4635\n",
      "Best model saved!\n",
      "Epoch [1000/1500], Loss: 0.3460\n",
      "Validation Loss: 0.4767\n",
      "Epoch [1010/1500], Loss: 0.2493\n",
      "Validation Loss: 0.4673\n",
      "Epoch [1020/1500], Loss: 0.3126\n",
      "Validation Loss: 0.4660\n",
      "Epoch [1030/1500], Loss: 0.3340\n",
      "Validation Loss: 0.4580\n",
      "Best model saved!\n",
      "Epoch [1040/1500], Loss: 0.3325\n",
      "Validation Loss: 0.4657\n",
      "Epoch [1050/1500], Loss: 0.2909\n",
      "Validation Loss: 0.4524\n",
      "Best model saved!\n",
      "Epoch [1060/1500], Loss: 0.2528\n",
      "Validation Loss: 0.4669\n",
      "Epoch [1070/1500], Loss: 0.2961\n",
      "Validation Loss: 0.4584\n",
      "Epoch [1080/1500], Loss: 0.2622\n",
      "Validation Loss: 0.4541\n",
      "Epoch [1090/1500], Loss: 0.3033\n",
      "Validation Loss: 0.4523\n",
      "Best model saved!\n",
      "Epoch [1100/1500], Loss: 0.2888\n",
      "Validation Loss: 0.4547\n",
      "Epoch [1110/1500], Loss: 0.3147\n",
      "Validation Loss: 0.4600\n",
      "Epoch [1120/1500], Loss: 0.3042\n",
      "Validation Loss: 0.4409\n",
      "Best model saved!\n",
      "Epoch [1130/1500], Loss: 0.2966\n",
      "Validation Loss: 0.4421\n",
      "Epoch [1140/1500], Loss: 0.3156\n",
      "Validation Loss: 0.4458\n",
      "Epoch [1150/1500], Loss: 0.2306\n",
      "Validation Loss: 0.4446\n",
      "Epoch [1160/1500], Loss: 0.3033\n",
      "Validation Loss: 0.4459\n",
      "Epoch [1170/1500], Loss: 0.2480\n",
      "Validation Loss: 0.4413\n",
      "Epoch [1180/1500], Loss: 0.2883\n",
      "Validation Loss: 0.4337\n",
      "Best model saved!\n",
      "Epoch [1190/1500], Loss: 0.3211\n",
      "Validation Loss: 0.4308\n",
      "Best model saved!\n",
      "Epoch [1200/1500], Loss: 0.2358\n",
      "Validation Loss: 0.4270\n",
      "Best model saved!\n",
      "Epoch [1210/1500], Loss: 0.1934\n",
      "Validation Loss: 0.4343\n",
      "Epoch [1220/1500], Loss: 0.2726\n",
      "Validation Loss: 0.4354\n",
      "Epoch [1230/1500], Loss: 0.2689\n",
      "Validation Loss: 0.4270\n",
      "Best model saved!\n",
      "Epoch [1240/1500], Loss: 0.2763\n",
      "Validation Loss: 0.4284\n",
      "Epoch [1250/1500], Loss: 0.2570\n",
      "Validation Loss: 0.4322\n",
      "Epoch [1260/1500], Loss: 0.2716\n",
      "Validation Loss: 0.4211\n",
      "Best model saved!\n",
      "Epoch [1270/1500], Loss: 0.2919\n",
      "Validation Loss: 0.4206\n",
      "Best model saved!\n",
      "Epoch [1280/1500], Loss: 0.2539\n",
      "Validation Loss: 0.4165\n",
      "Best model saved!\n",
      "Epoch [1290/1500], Loss: 0.2652\n",
      "Validation Loss: 0.4143\n",
      "Best model saved!\n",
      "Epoch [1300/1500], Loss: 0.2383\n",
      "Validation Loss: 0.4156\n",
      "Epoch [1310/1500], Loss: 0.2266\n",
      "Validation Loss: 0.4075\n",
      "Best model saved!\n",
      "Epoch [1320/1500], Loss: 0.2570\n",
      "Validation Loss: 0.4198\n",
      "Epoch [1330/1500], Loss: 0.2683\n",
      "Validation Loss: 0.4189\n",
      "Epoch [1340/1500], Loss: 0.2748\n",
      "Validation Loss: 0.4112\n",
      "Epoch [1350/1500], Loss: 0.2305\n",
      "Validation Loss: 0.4071\n",
      "Best model saved!\n",
      "Epoch [1360/1500], Loss: 0.2517\n",
      "Validation Loss: 0.4049\n",
      "Best model saved!\n",
      "Epoch [1370/1500], Loss: 0.2668\n",
      "Validation Loss: 0.4102\n",
      "Epoch [1380/1500], Loss: 0.2909\n",
      "Validation Loss: 0.3999\n",
      "Best model saved!\n",
      "Epoch [1390/1500], Loss: 0.2337\n",
      "Validation Loss: 0.3990\n",
      "Best model saved!\n",
      "Epoch [1400/1500], Loss: 0.2384\n",
      "Validation Loss: 0.3979\n",
      "Best model saved!\n",
      "Epoch [1410/1500], Loss: 0.2321\n",
      "Validation Loss: 0.4034\n",
      "Epoch [1420/1500], Loss: 0.2602\n",
      "Validation Loss: 0.3999\n",
      "Epoch [1430/1500], Loss: 0.2220\n",
      "Validation Loss: 0.3919\n",
      "Best model saved!\n",
      "Epoch [1440/1500], Loss: 0.2227\n",
      "Validation Loss: 0.3941\n",
      "Epoch [1450/1500], Loss: 0.2867\n",
      "Validation Loss: 0.3922\n",
      "Epoch [1460/1500], Loss: 0.1777\n",
      "Validation Loss: 0.3913\n",
      "Best model saved!\n",
      "Epoch [1470/1500], Loss: 0.2254\n",
      "Validation Loss: 0.3979\n",
      "Epoch [1480/1500], Loss: 0.2498\n",
      "Validation Loss: 0.3852\n",
      "Best model saved!\n",
      "Epoch [1490/1500], Loss: 0.2567\n",
      "Validation Loss: 0.3905\n",
      "Epoch [1500/1500], Loss: 0.2098\n",
      "Validation Loss: 0.3790\n",
      "Best model saved!\n"
     ]
    }
   ],
   "source": [
    "# Visualize the optimization history\n",
    "optuna.visualization.plot_optimization_history(study).show()\n",
    "\n",
    "# Visualize the importance of each hyperparameter\n",
    "optuna.visualization.plot_param_importances(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aba731c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded the best_model.pth after training is complete\n",
    "best_model_path = 'best_model.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        test_outputs = model(test_inputs)\n",
    "        _, predicted = torch.max(test_outputs.data, 1)\n",
    "        total += test_labels.size(0)\n",
    "        correct += (predicted == test_labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test data: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24408d42",
   "metadata": {},
   "source": [
    "test now with half of the dataset of size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30ddc01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 4]) torch.Size([150])\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "# shuffle dataset before split\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(iris.data))\n",
    "iris.data = iris.data[indices]\n",
    "iris.target = iris.target[indices]\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "full_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# split with label and unlabel data. Assume 20% labeled data\n",
    "label_data, unlabel_data = train_test_split(full_dataset, test_size=0.8, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(label_data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data, validation_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "print(X_tensor.shape, y_tensor.shape)\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size = 1024\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size_train, shuffle=True)\n",
    "val_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "unlabeled_loader = DataLoader(unlabel_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5e46c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "output_size = 3\n",
    "model = SimpleNN(input_size, output_size)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae0f2805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Best model saved!\n",
      "Epoch [20/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [30/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [40/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [50/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [60/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [70/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [80/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [90/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [100/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [110/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [120/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [130/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [140/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [150/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [160/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [170/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [180/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [190/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [200/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [210/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [220/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [230/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [240/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [250/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [260/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [270/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [280/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [290/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [300/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [310/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [320/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [330/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [340/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [350/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [360/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [370/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [380/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [390/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [400/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [410/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [420/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [430/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [440/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [450/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [460/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [470/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [480/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [490/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [500/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [510/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [520/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [530/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [540/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [550/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [560/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [570/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [580/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [590/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [600/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [610/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [620/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [630/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [640/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [650/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [660/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [670/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [680/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [690/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [700/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [710/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [720/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [730/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [740/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [750/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [760/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [770/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [780/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [790/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [800/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [810/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [820/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [830/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [840/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [850/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [860/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [870/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [880/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [890/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [900/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [910/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [920/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [930/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [940/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [950/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [960/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [970/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [980/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [990/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1000/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1010/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1020/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1030/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1040/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1050/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1060/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1070/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1080/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1090/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1100/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1110/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1120/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1130/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1140/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1150/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1160/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1170/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1180/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1190/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1200/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1210/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1220/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1230/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1240/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1250/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1260/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1270/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1280/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1290/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1300/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1310/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1320/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1330/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1340/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1350/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1360/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1370/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1380/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1390/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1400/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1410/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1420/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1430/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1440/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1450/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1460/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1470/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1480/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1490/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n",
      "Epoch [1500/1500], Loss: 0.4211\n",
      "Validation Loss: 0.5308\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1500\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = loss_function(val_outputs, val_labels)\n",
    "                val_losses.append(val_loss.item())\n",
    "            avg_val_loss = np.mean(val_losses)\n",
    "            print(f'Validation Loss: {avg_val_loss:.4f}')\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), 'best_model_label.pth')\n",
    "                print('Best model saved!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "865e3e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 66.67%\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded the best_model.pth after training is complete\n",
    "best_model_path = 'best_model_label.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        test_outputs = model(test_inputs)\n",
    "        _, predicted = torch.max(test_outputs.data, 1)\n",
    "        total += test_labels.size(0)\n",
    "        correct += (predicted == test_labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test data: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "36bf8c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the unlabel data: 79.17%\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded the best_model.pth after training is complete\n",
    "best_model_path = 'best_model_label.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for unlabel_inputs, unlabel_labels in unlabeled_loader:\n",
    "        unlabel_outputs = model(unlabel_inputs)\n",
    "        _, predicted = torch.max(unlabel_outputs.data, 1)\n",
    "        total += unlabel_labels.size(0)\n",
    "        correct += (predicted == unlabel_labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the unlabel data: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80514f4d",
   "metadata": {},
   "source": [
    "try using mean teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "257b133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73bc7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_teacher_weights(student_model, teacher_model, alpha=0.99):\n",
    "    for teacher_param, student_param in zip(teacher_model.parameters(), student_model.parameters()):\n",
    "        teacher_param.data.mul_(alpha).add_(student_param.data, alpha=1 - alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "464261bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "output_size = 3\n",
    "student_model = SimpleNN(input_size, output_size)\n",
    "# Instantiate the teacher model with the same architecture\n",
    "teacher_model = copy.deepcopy(student_model)\n",
    "\n",
    "# The teacher model should not have its gradients calculated\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "supervised_loss_fn = nn.CrossEntropyLoss()\n",
    "consistency_loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n",
    "alpha = 0.99  # for exponential moving average\n",
    "lambda_u = 0.3  # weight for unlabeled loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9260662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4411fc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 1.2190\n",
      "Validation Loss: 1.5891\n",
      "Best model saved!\n",
      "Epoch [20/1000], Loss: 1.1657\n",
      "Validation Loss: 1.5130\n",
      "Best model saved!\n",
      "Epoch [30/1000], Loss: 1.1193\n",
      "Validation Loss: 1.4467\n",
      "Best model saved!\n",
      "Epoch [40/1000], Loss: 1.0793\n",
      "Validation Loss: 1.3888\n",
      "Best model saved!\n",
      "Epoch [50/1000], Loss: 1.0418\n",
      "Validation Loss: 1.3376\n",
      "Best model saved!\n",
      "Epoch [60/1000], Loss: 1.0052\n",
      "Validation Loss: 1.2921\n",
      "Best model saved!\n",
      "Epoch [70/1000], Loss: 0.9700\n",
      "Validation Loss: 1.2502\n",
      "Best model saved!\n",
      "Epoch [80/1000], Loss: 0.9366\n",
      "Validation Loss: 1.2105\n",
      "Best model saved!\n",
      "Epoch [90/1000], Loss: 0.9044\n",
      "Validation Loss: 1.1729\n",
      "Best model saved!\n",
      "Epoch [100/1000], Loss: 0.8738\n",
      "Validation Loss: 1.1370\n",
      "Best model saved!\n",
      "Epoch [110/1000], Loss: 0.8433\n",
      "Validation Loss: 1.1026\n",
      "Best model saved!\n",
      "Epoch [120/1000], Loss: 0.8161\n",
      "Validation Loss: 1.0700\n",
      "Best model saved!\n",
      "Epoch [130/1000], Loss: 0.7900\n",
      "Validation Loss: 1.0390\n",
      "Best model saved!\n",
      "Epoch [140/1000], Loss: 0.7647\n",
      "Validation Loss: 1.0096\n",
      "Best model saved!\n",
      "Epoch [150/1000], Loss: 0.7398\n",
      "Validation Loss: 0.9818\n",
      "Best model saved!\n",
      "Epoch [160/1000], Loss: 0.7147\n",
      "Validation Loss: 0.9555\n",
      "Best model saved!\n",
      "Epoch [170/1000], Loss: 0.6915\n",
      "Validation Loss: 0.9307\n",
      "Best model saved!\n",
      "Epoch [180/1000], Loss: 0.6701\n",
      "Validation Loss: 0.9072\n",
      "Best model saved!\n",
      "Epoch [190/1000], Loss: 0.6517\n",
      "Validation Loss: 0.8851\n",
      "Best model saved!\n",
      "Epoch [200/1000], Loss: 0.6302\n",
      "Validation Loss: 0.8647\n",
      "Best model saved!\n",
      "Epoch [210/1000], Loss: 0.6137\n",
      "Validation Loss: 0.8455\n",
      "Best model saved!\n",
      "Epoch [220/1000], Loss: 0.5970\n",
      "Validation Loss: 0.8275\n",
      "Best model saved!\n",
      "Epoch [230/1000], Loss: 0.5823\n",
      "Validation Loss: 0.8105\n",
      "Best model saved!\n",
      "Epoch [240/1000], Loss: 0.5695\n",
      "Validation Loss: 0.7947\n",
      "Best model saved!\n",
      "Epoch [250/1000], Loss: 0.5541\n",
      "Validation Loss: 0.7799\n",
      "Best model saved!\n",
      "Epoch [260/1000], Loss: 0.5424\n",
      "Validation Loss: 0.7656\n",
      "Best model saved!\n",
      "Epoch [270/1000], Loss: 0.5303\n",
      "Validation Loss: 0.7523\n",
      "Best model saved!\n",
      "Epoch [280/1000], Loss: 0.5177\n",
      "Validation Loss: 0.7402\n",
      "Best model saved!\n",
      "Epoch [290/1000], Loss: 0.5079\n",
      "Validation Loss: 0.7287\n",
      "Best model saved!\n",
      "Epoch [300/1000], Loss: 0.4968\n",
      "Validation Loss: 0.7177\n",
      "Best model saved!\n",
      "Epoch [310/1000], Loss: 0.4886\n",
      "Validation Loss: 0.7074\n",
      "Best model saved!\n",
      "Epoch [320/1000], Loss: 0.4786\n",
      "Validation Loss: 0.6976\n",
      "Best model saved!\n",
      "Epoch [330/1000], Loss: 0.4700\n",
      "Validation Loss: 0.6887\n",
      "Best model saved!\n",
      "Epoch [340/1000], Loss: 0.4629\n",
      "Validation Loss: 0.6802\n",
      "Best model saved!\n",
      "Epoch [350/1000], Loss: 0.4565\n",
      "Validation Loss: 0.6723\n",
      "Best model saved!\n",
      "Epoch [360/1000], Loss: 0.4470\n",
      "Validation Loss: 0.6648\n",
      "Best model saved!\n",
      "Epoch [370/1000], Loss: 0.4420\n",
      "Validation Loss: 0.6569\n",
      "Best model saved!\n",
      "Epoch [380/1000], Loss: 0.4344\n",
      "Validation Loss: 0.6499\n",
      "Best model saved!\n",
      "Epoch [390/1000], Loss: 0.4275\n",
      "Validation Loss: 0.6439\n",
      "Best model saved!\n",
      "Epoch [400/1000], Loss: 0.4213\n",
      "Validation Loss: 0.6376\n",
      "Best model saved!\n",
      "Epoch [410/1000], Loss: 0.4188\n",
      "Validation Loss: 0.6315\n",
      "Best model saved!\n",
      "Epoch [420/1000], Loss: 0.4125\n",
      "Validation Loss: 0.6259\n",
      "Best model saved!\n",
      "Epoch [430/1000], Loss: 0.4083\n",
      "Validation Loss: 0.6207\n",
      "Best model saved!\n",
      "Epoch [440/1000], Loss: 0.4032\n",
      "Validation Loss: 0.6155\n",
      "Best model saved!\n",
      "Epoch [450/1000], Loss: 0.3974\n",
      "Validation Loss: 0.6104\n",
      "Best model saved!\n",
      "Epoch [460/1000], Loss: 0.3935\n",
      "Validation Loss: 0.6057\n",
      "Best model saved!\n",
      "Epoch [470/1000], Loss: 0.3886\n",
      "Validation Loss: 0.6015\n",
      "Best model saved!\n",
      "Epoch [480/1000], Loss: 0.3850\n",
      "Validation Loss: 0.5969\n",
      "Best model saved!\n",
      "Epoch [490/1000], Loss: 0.3800\n",
      "Validation Loss: 0.5928\n",
      "Best model saved!\n",
      "Epoch [500/1000], Loss: 0.3781\n",
      "Validation Loss: 0.5887\n",
      "Best model saved!\n",
      "Epoch [510/1000], Loss: 0.3737\n",
      "Validation Loss: 0.5850\n",
      "Best model saved!\n",
      "Epoch [520/1000], Loss: 0.3697\n",
      "Validation Loss: 0.5811\n",
      "Best model saved!\n",
      "Epoch [530/1000], Loss: 0.3649\n",
      "Validation Loss: 0.5775\n",
      "Best model saved!\n",
      "Epoch [540/1000], Loss: 0.3636\n",
      "Validation Loss: 0.5741\n",
      "Best model saved!\n",
      "Epoch [550/1000], Loss: 0.3590\n",
      "Validation Loss: 0.5709\n",
      "Best model saved!\n",
      "Epoch [560/1000], Loss: 0.3558\n",
      "Validation Loss: 0.5674\n",
      "Best model saved!\n",
      "Epoch [570/1000], Loss: 0.3528\n",
      "Validation Loss: 0.5644\n",
      "Best model saved!\n",
      "Epoch [580/1000], Loss: 0.3500\n",
      "Validation Loss: 0.5614\n",
      "Best model saved!\n",
      "Epoch [590/1000], Loss: 0.3496\n",
      "Validation Loss: 0.5585\n",
      "Best model saved!\n",
      "Epoch [600/1000], Loss: 0.3466\n",
      "Validation Loss: 0.5554\n",
      "Best model saved!\n",
      "Epoch [610/1000], Loss: 0.3418\n",
      "Validation Loss: 0.5526\n",
      "Best model saved!\n",
      "Epoch [620/1000], Loss: 0.3403\n",
      "Validation Loss: 0.5499\n",
      "Best model saved!\n",
      "Epoch [630/1000], Loss: 0.3370\n",
      "Validation Loss: 0.5472\n",
      "Best model saved!\n",
      "Epoch [640/1000], Loss: 0.3325\n",
      "Validation Loss: 0.5448\n",
      "Best model saved!\n",
      "Epoch [650/1000], Loss: 0.3306\n",
      "Validation Loss: 0.5421\n",
      "Best model saved!\n",
      "Epoch [660/1000], Loss: 0.3296\n",
      "Validation Loss: 0.5399\n",
      "Best model saved!\n",
      "Epoch [670/1000], Loss: 0.3266\n",
      "Validation Loss: 0.5376\n",
      "Best model saved!\n",
      "Epoch [680/1000], Loss: 0.3263\n",
      "Validation Loss: 0.5350\n",
      "Best model saved!\n",
      "Epoch [690/1000], Loss: 0.3231\n",
      "Validation Loss: 0.5330\n",
      "Best model saved!\n",
      "Epoch [700/1000], Loss: 0.3217\n",
      "Validation Loss: 0.5310\n",
      "Best model saved!\n",
      "Epoch [710/1000], Loss: 0.3179\n",
      "Validation Loss: 0.5288\n",
      "Best model saved!\n",
      "Epoch [720/1000], Loss: 0.3153\n",
      "Validation Loss: 0.5267\n",
      "Best model saved!\n",
      "Epoch [730/1000], Loss: 0.3120\n",
      "Validation Loss: 0.5247\n",
      "Best model saved!\n",
      "Epoch [740/1000], Loss: 0.3132\n",
      "Validation Loss: 0.5227\n",
      "Best model saved!\n",
      "Epoch [750/1000], Loss: 0.3091\n",
      "Validation Loss: 0.5206\n",
      "Best model saved!\n",
      "Epoch [760/1000], Loss: 0.3103\n",
      "Validation Loss: 0.5185\n",
      "Best model saved!\n",
      "Epoch [770/1000], Loss: 0.3066\n",
      "Validation Loss: 0.5169\n",
      "Best model saved!\n",
      "Epoch [780/1000], Loss: 0.3040\n",
      "Validation Loss: 0.5150\n",
      "Best model saved!\n",
      "Epoch [790/1000], Loss: 0.3014\n",
      "Validation Loss: 0.5130\n",
      "Best model saved!\n",
      "Epoch [800/1000], Loss: 0.2994\n",
      "Validation Loss: 0.5111\n",
      "Best model saved!\n",
      "Epoch [810/1000], Loss: 0.2975\n",
      "Validation Loss: 0.5096\n",
      "Best model saved!\n",
      "Epoch [820/1000], Loss: 0.2963\n",
      "Validation Loss: 0.5078\n",
      "Best model saved!\n",
      "Epoch [830/1000], Loss: 0.2953\n",
      "Validation Loss: 0.5060\n",
      "Best model saved!\n",
      "Epoch [840/1000], Loss: 0.2937\n",
      "Validation Loss: 0.5046\n",
      "Best model saved!\n",
      "Epoch [850/1000], Loss: 0.2905\n",
      "Validation Loss: 0.5030\n",
      "Best model saved!\n",
      "Epoch [860/1000], Loss: 0.2890\n",
      "Validation Loss: 0.5013\n",
      "Best model saved!\n",
      "Epoch [870/1000], Loss: 0.2865\n",
      "Validation Loss: 0.4999\n",
      "Best model saved!\n",
      "Epoch [880/1000], Loss: 0.2875\n",
      "Validation Loss: 0.4984\n",
      "Best model saved!\n",
      "Epoch [890/1000], Loss: 0.2848\n",
      "Validation Loss: 0.4967\n",
      "Best model saved!\n",
      "Epoch [900/1000], Loss: 0.2835\n",
      "Validation Loss: 0.4953\n",
      "Best model saved!\n",
      "Epoch [910/1000], Loss: 0.2833\n",
      "Validation Loss: 0.4939\n",
      "Best model saved!\n",
      "Epoch [920/1000], Loss: 0.2808\n",
      "Validation Loss: 0.4925\n",
      "Best model saved!\n",
      "Epoch [930/1000], Loss: 0.2789\n",
      "Validation Loss: 0.4912\n",
      "Best model saved!\n",
      "Epoch [940/1000], Loss: 0.2772\n",
      "Validation Loss: 0.4897\n",
      "Best model saved!\n",
      "Epoch [950/1000], Loss: 0.2762\n",
      "Validation Loss: 0.4884\n",
      "Best model saved!\n",
      "Epoch [960/1000], Loss: 0.2720\n",
      "Validation Loss: 0.4872\n",
      "Best model saved!\n",
      "Epoch [970/1000], Loss: 0.2719\n",
      "Validation Loss: 0.4857\n",
      "Best model saved!\n",
      "Epoch [980/1000], Loss: 0.2713\n",
      "Validation Loss: 0.4842\n",
      "Best model saved!\n",
      "Epoch [990/1000], Loss: 0.2703\n",
      "Validation Loss: 0.4833\n",
      "Best model saved!\n",
      "Epoch [1000/1000], Loss: 0.2667\n",
      "Validation Loss: 0.4820\n",
      "Best model saved!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 1000\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    student_model.train()\n",
    "    for (labeled_data, labeled_labels), (unlabeled_data,_) in zip(cycle(train_loader), unlabeled_loader):\n",
    "        # Supervised loss\n",
    "        labeled_outputs = student_model(labeled_data)\n",
    "        supervised_loss = supervised_loss_fn(labeled_outputs, labeled_labels)\n",
    "        \n",
    "        # 1. Weakly augmented view for the TEACHER\n",
    "        unlabeled_data_teacher = add_gaussian_noise(unlabeled_data, std=0.05)\n",
    "        \n",
    "        # 2. Strongly augmented view for the STUDENT\n",
    "        unlabeled_data_student = add_gaussian_noise(unlabeled_data, std=0.15)\n",
    "        \n",
    "        # Consistency loss\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(unlabeled_data_teacher)\n",
    "        student_outputs_unlabeled = student_model(unlabeled_data_student)\n",
    "        consistency_loss = consistency_loss_fn(student_outputs_unlabeled, teacher_outputs)\n",
    "\n",
    "        total_loss = supervised_loss + lambda_u * consistency_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update teacher model's weights using EMA\n",
    "        update_teacher_weights(student_model, teacher_model)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss .item():.4f}')\n",
    "            # Evaluate on validation set\n",
    "            student_model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_losses = []\n",
    "                for val_inputs, val_labels in val_loader:\n",
    "                    val_outputs = student_model(val_inputs)\n",
    "                    val_loss = loss_function(val_outputs, val_labels)\n",
    "                    val_losses.append(val_loss.item())\n",
    "                avg_val_loss = np.mean(val_losses)\n",
    "                print(f'Validation Loss: {avg_val_loss:.4f}')\n",
    "                if avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    torch.save(student_model.state_dict(), 'best_model_label_and_unlabel.pth')\n",
    "                    print('Best model saved!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "35cf9702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded the best_model.pth after training is complete\n",
    "best_model_path = 'best_model_label_and_unlabel.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        test_outputs = model(test_inputs)\n",
    "        _, predicted = torch.max(test_outputs.data, 1)\n",
    "        total += test_labels.size(0)\n",
    "        correct += (predicted == test_labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test data: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "df547014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the unlabel data: 95.00%\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded the best_model.pth after training is complete\n",
    "best_model_path = 'best_model_label_and_unlabel.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for unlabel_inputs, unlabel_labels in unlabeled_loader:\n",
    "        unlabel_outputs = model(unlabel_inputs)\n",
    "        _, predicted = torch.max(unlabel_outputs.data, 1)\n",
    "        total += unlabel_labels.size(0)\n",
    "        correct += (predicted == unlabel_labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the unlabel data: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semi-supervised-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
